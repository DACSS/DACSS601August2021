[
  {
    "path": "posts/2021-08-20-using-a-function-to-read-active-duty-marital-data/",
    "title": "Using A Function to Read Active Duty Marital Data",
    "description": "This is the example code to use a new custom function to read in multiple sheets of data about Active Duty members of the military and marital status.",
    "author": [
      {
        "name": "Sean Conway and Meredith Rolfe",
        "url": {}
      }
    ],
    "date": "2021-08-20",
    "categories": [
      "example code",
      "cleaning data",
      "programming functions"
    ],
    "contents": "\nThis is a quick piece of example code to read in the active duty marital status tables from Excel. This example code builds on the earlier examples of reading in Excel tables by creating a function and applying it to multiple sheets.\nCleaning a single sheet\nWe will start off by cleaning a single sheet from the workbook, trying to create a set of generic functions that can be used to iterate through all sheets in the workbook to read them one after the other. To read the single sheet, follow the same process we followed in *Reading in Tabular Data.\"\nIdentify grouping variables and values to extract from the table\nLets first look at an example sheet from the workbook.\nTotal DOD Active Duty Marital SheetWe can see a few things from this example sheet. First, we will need to skip 8 or 9 rows - the data first appears in row 10. Second, the tabular cells represent count values that capture the number of employees falling into subcategories created by 6 distinct grouping values: 1) Pay Grade Type: Enlisted/Officer/Warrent Officer 2) Pay Grade Level: 1-10 (fewer for non-Enlisted) 3) Marital status: Married/Single 4) Parent: Kids/noKids (Single only) 5) Spouse affiliation: Civilian/Military (Married only) 6) Gender: Male/Female\nOur goal is to recover cases that have these 6 (or really 5, if we collapse parent and spouse variables as we don’t have complete information) grouping variables to identify the case and the single value (count of active duty employees who fall into each of the resulting subcategories.)\nLooking back at the original excel sheet, we can see that we will need to not just skip the top rows, we will also need to delete several columns, and also rename variables in order to make it easy to separate out the three pieces of information contained in the column names. First, I create a vector with column names (to make it easier to reuse later in the functional programming) then I read in the data and inspect it to see if the columns worked as intended.\n\n\nmarital <-c(\"d\", \"payGrade_payLevel\",\n            \"single_nokids_male\", \"single_nokids_female\", \"d\",\n            \"single_kids_male\", \"single_kids_female\", \"d\",\n            \"married_military_male\", \"married_military_female\", \"d\",\n            \"married_civilian_male\", \"married_civilian_female\", \"d\",\n            rep(\"d\", 3))\nread_excel(\"../../_data/ActiveDuty_MaritalStatus.xls\", \n           skip=8,\n           col_names = marital\n           )\n\n\n# A tibble: 31 × 17\n   d...1 payGrade_payLevel single_nokids_male single_nokids_fem… d...5\n   <chr> <chr>             <chr>              <chr>              <chr>\n 1 <NA>  Pay Grade         Male               Female             Total\n 2 <NA>  E-1               31229              5717               36946\n 3 <NA>  E-2               53094              8388               61482\n 4 <NA>  E-3               131091             21019              1521…\n 5 <NA>  E-4               112710             16381              1290…\n 6 <NA>  E-5               57989              11021              69010\n 7 <NA>  E-6               19125              4654               23779\n 8 <NA>  E-7               5446               1913               7359 \n 9 <NA>  E-8               1009               438                1447 \n10 <NA>  E-9               381                202                583  \n# … with 21 more rows, and 12 more variables: single_kids_male <chr>,\n#   single_kids_female <chr>, d...8 <chr>,\n#   married_military_male <chr>, married_military_female <chr>,\n#   d...11 <chr>, married_civilian_male <chr>,\n#   married_civilian_female <chr>, d...14 <chr>, d...15 <chr>,\n#   d...16 <chr>, d...17 <chr>\n\nI can see that the variable names worked well, so this time I will read in the data and omit the original header row, and also filter out the various “TOTAL” rows that we don’t need to keep.\n\n\nmilitary<-read_excel(\"../../_data/ActiveDuty_MaritalStatus.xls\", \n           skip=9,\n           col_names = marital\n           )%>%\n  select(!starts_with(\"d\"))%>%\n  filter(str_detect(payGrade_payLevel, \"TOTAL\", negate=TRUE))\nmilitary\n\n\n# A tibble: 24 × 9\n   payGrade_payLev… single_nokids_m… single_nokids_f… single_kids_male\n   <chr>                       <dbl>            <dbl>            <dbl>\n 1 E-1                         31229             5717              563\n 2 E-2                         53094             8388             1457\n 3 E-3                        131091            21019             4264\n 4 E-4                        112710            16381             9491\n 5 E-5                         57989            11021            10937\n 6 E-6                         19125             4654            10369\n 7 E-7                          5446             1913             6530\n 8 E-8                          1009              438             1786\n 9 E-9                           381              202              579\n10 O-1                         13495             3081              402\n# … with 14 more rows, and 5 more variables:\n#   single_kids_female <dbl>, married_military_male <dbl>,\n#   married_military_female <dbl>, married_civilian_male <dbl>,\n#   married_civilian_female <dbl>\n\nIt looks like this worked well! Now we just need to pivot_longer with 3 columns (similar to what we did in the Tabular Data example). Then we will separate out the information in the payGrade_payLevel variable and do a quick mutate to make paygrade easier to remember.\n\n\nmilitary_long <-military %>%\n  pivot_longer(cols = -1,\n               names_to = c(\"Marital\", \"Other\", \"Gender\"),\n               names_sep = \"_\",\n               values_to = \"count\")%>%\n  separate(payGrade_payLevel, \n           into = c(\"payGrade\", \"payLevel\"),\n           sep=\"-\")%>%\n  mutate(payGrade = case_when(\n    payGrade == \"E\" ~ \"Enlisted\",\n    payGrade == \"O\" ~ \"Officer\",\n    payGrade == \"W\" ~ \"Warrant Officer\"\n  ))\nmilitary_long\n\n\n# A tibble: 192 × 6\n   payGrade payLevel Marital Other    Gender count\n   <chr>    <chr>    <chr>   <chr>    <chr>  <dbl>\n 1 Enlisted 1        single  nokids   male   31229\n 2 Enlisted 1        single  nokids   female  5717\n 3 Enlisted 1        single  kids     male     563\n 4 Enlisted 1        single  kids     female   122\n 5 Enlisted 1        married military male     139\n 6 Enlisted 1        married military female   141\n 7 Enlisted 1        married civilian male    5060\n 8 Enlisted 1        married civilian female   719\n 9 Enlisted 2        single  nokids   male   53094\n10 Enlisted 2        single  nokids   female  8388\n# … with 182 more rows\n\nThis all looks like it works well. So now we will go on to creating a function with the steps, then applying it to multiple sheets.\nCreate a new function\nWe will call our new function read_military, and we will basically use the exact same commands as above. The big difference is that we will have a placeholder name (or argument) for the data sheet that will be passed to the new function.\nNext we have to use read_excel(), but we have to specify a number of arguments. We first specify the path (note - file_path is a variable that I created ahead of time to be specific to my computer. Yours will be different). Next, we specify sheet, the number of the sheet we wish to read in (we can also specify the sheet name). We also need to manually specify col_names from our marital vector that we created above.\nmutate() creates a new column called branch, which comes from our sheet name. select(!starts_with(\"d\")) removes all columns that start with \"d\". We also filter out the word “Total” from payGrade_payLevel. pivot_longer()\n\n\nread_military<-function(sheet_name){\n  read_excel(\"../../_data/ActiveDuty_MaritalStatus.xls\", \n             sheet = sheet_name,\n             skip=9,\n             col_names = marital\n             )%>%\n  mutate(\"branch\"=sheet_name) %>%\n  select(!starts_with(\"d\"))%>%\n  filter(str_detect(payGrade_payLevel, \"TOTAL\", negate=TRUE))%>%\n  pivot_longer(cols = contains(c(\"male\", \"female\")),\n               names_to = c(\"Marital\", \"Other\", \"Gender\"),\n               names_sep = \"_\",\n               values_to = \"count\")%>%\n  separate(payGrade_payLevel, \n           into = c(\"payGrade\", \"payLevel\"),\n           sep=\"-\")%>%\n  mutate(payGrade = case_when(\n    payGrade == \"E\" ~ \"Enlisted\",\n    payGrade == \"O\" ~ \"Officer\",\n    payGrade == \"W\" ~ \"Warrant Officer\"\n  ))\n}\n\n\n\nWe now have a function that is customized to read in the mmilitary active duty marital status sheets. We just need to use purrr - a package that is part of tidyverse but which may need to be installed and loaded on its own - to iterate through the list of sheets in the workbook.\n\n\nexcel_sheets(\"../../_data/ActiveDuty_MaritalStatus.xls\")\n\n\n[1] \"TotalDoD\"    \"AirForce\"    \"MarineCorps\" \"Navy\"       \n[5] \"Army\"       \n\nmap_dfr(\n  excel_sheets(\"../../_data/ActiveDuty_MaritalStatus.xls\")[2:5],\n  read_military)\n\n\n# A tibble: 720 × 7\n   payGrade payLevel branch   Marital Other    Gender count\n   <chr>    <chr>    <chr>    <chr>   <chr>    <chr>  <dbl>\n 1 Enlisted 1        AirForce single  nokids   male    7721\n 2 Enlisted 1        AirForce single  nokids   female  1550\n 3 Enlisted 1        AirForce single  kids     male      27\n 4 Enlisted 1        AirForce single  kids     female     5\n 5 Enlisted 1        AirForce married military male      49\n 6 Enlisted 1        AirForce married military female    27\n 7 Enlisted 1        AirForce married civilian male    1064\n 8 Enlisted 1        AirForce married civilian female   178\n 9 Enlisted 2        AirForce single  nokids   male    4380\n10 Enlisted 2        AirForce single  nokids   female  1010\n# … with 710 more rows\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:47:13-04:00",
    "input_file": "using-a-function-to-read-active-duty-marital-data.knit.md"
  },
  {
    "path": "posts/2021-08-20-active-duty-marital-status/",
    "title": "Active Duty Marital Status",
    "description": "A short description of the post.",
    "author": [],
    "date": "2021-08-20",
    "categories": [],
    "contents": "\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:47:01-04:00",
    "input_file": "active-duty-marital-status.knit.md"
  },
  {
    "path": "posts/2021-08-20-homework3-functions-by-mm/",
    "title": "Homework3: Functions by MM",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Michelle Manning",
        "url": {}
      }
    ],
    "date": "2021-08-20",
    "categories": [],
    "contents": "\nFirst, I loaded in the packages and files I needed.I am using the poultry data set for this project.\n\n\nlibrary(blogbuilder)\nlibrary(distill)\nlibrary(tidyverse)\npoultry <- read.csv(file=\"../../_data/poultry_tidy.csv\")\nlibrary(usethis)\n\n\n\nI first used the functions select, filter, and arrange. I saved sumarize for when I ran the function group_by to highlight the function’s use. After those, I used rename, case_when, across, pivot_longer and wider, purrr, and lapply.\n\n\n#Functions\n#select, filter, arrange\npoultry2 <- poultry %>% \n  select(Product, Year, Price_Dollar) %>% \n  filter(Product == \"Whole\") %>% \n  arrange(Product, Price_Dollar, Year)\nhead(poultry2)  \n\n\n  Product Year Price_Dollar\n1   Whole 2004      1.97500\n2   Whole 2004      1.97500\n3   Whole 2004      2.09000\n4   Whole 2004      2.12000\n5   Whole 2004      2.14500\n6   Whole 2004      2.16375\n\nhead(poultry)\n\n\n  Product Year    Month Price_Dollar\n1   Whole 2013  January        2.385\n2   Whole 2013 February        2.385\n3   Whole 2013    March        2.385\n4   Whole 2013    April        2.385\n5   Whole 2013      May        2.385\n6   Whole 2013     June        2.385\n\n#Optional Functions\n#group_by & summarize\npoultry_grouped <- poultry2 %>% \n  group_by(Year)\nsummarise(poultry_grouped, Year = mean(Year))\n\n\n# A tibble: 10 × 1\n    Year\n   <dbl>\n 1  2004\n 2  2005\n 3  2006\n 4  2007\n 5  2008\n 6  2009\n 7  2010\n 8  2011\n 9  2012\n10  2013\n\n#rename\ncolnames(poultry2)\n\n\n[1] \"Product\"      \"Year\"         \"Price_Dollar\"\n\npoultry3 <- poultry2 %>%\n  rename(Price=Price_Dollar)\n#case_when  \nmean(poultry3$Price)\n\n\n[1] 2.305333\n\npoultry4 <- poultry2 %>%\n  mutate(Above.Below.Avg = case_when(Price_Dollar >= 2.305333 ~\"Above Mean\", TRUE ~ \"Below Mean\"))\n#across\npoultry5 <- poultry2 %>%\n  group_by(Year) %>%\n  summarise(across(starts_with(\"Price_Dollar\"), list(mean = mean, sd = sd)))\n#Pivoting\npoultry_wider <- poultry %>% \n  pivot_wider(names_from = \"Product\",values_from = \"Price_Dollar\")\npoultry_longer <- poultry_wider %>% \n  pivot_longer(Whole:Thighs, names_to = \"Product\", values_to = \"Price_Dollar\")\n#purrr\nlibrary(stringr)\navg_fun <- function(x)\npurrr::map_dbl(poultry3, n_distinct)\n#lapply\npoultry_upper <- lapply(poultry2$Product, toupper)\nstr(poultry_upper)\n\n\nList of 120\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n $ : chr \"WHOLE\"\n  [list output truncated]\n\nI decided to use ggplot to edify my knowledge of it. Here is the poultry’s Product variable’s price plotted by the month and year.\n\n\n#plotting\nggplot(data = poultry, mapping = aes(x=Month, y = Price_Dollar, color = Product, group = Product))+ \n  geom_point()+ \n  geom_line() +\n  facet_grid(~Year)\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-08-20-homework3-functions-by-mm/homework3-functions-by-mm_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2021-08-20T15:47:07-04:00",
    "input_file": "homework3-functions-by-mm.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-08-17-railroad-county-tracy/",
    "title": "RAILROAD-COUNTY-TRACY",
    "description": "Homework assignment 1, 2 and 3. Loading data into an R Markdown file, Railroad Employment Data.",
    "author": [
      {
        "name": "Erin-Tracy",
        "url": {}
      }
    ],
    "date": "2021-08-19",
    "categories": [],
    "contents": "\nHOMEWORK 2\nTotal Railroad Employment by State and County 2012 breaks down US railroad employment numbers in 2012 by state and county. This dataset explores railroads.\nIt has 120 2930 observations and 63 variables.\nThe three variables are state, county and total employees. I chose to specifically study counties with a very large number of railroad employees. Separately, I also looked into railroad employee numbers just in the New England states.\nSource\nThe dataset is sourced from (https://catalog.data.gov/dataset/total-railroad-employment-by-state-and-county-2012/resource/5a0b2831-23b9-4ce9-82e9-87a7d8f2c5d8)\nFor now, Echo is TRUE, for final version change to FALSE\n\n\nknitr::opts_chunk$set(echo = TRUE)\n\nlibrary(\"tidyverse\")\nlibrary(\"readr\")\nlibrary(\"ggplot2\")\nlibrary(\"dplyr\")\nknitr::opts_chunk$set(fig.width = 5, fig.asp = 1/3)\n\n\n\nHOMEWORK 1 Here I am reading in my CSV file.\n\n\ndata<-read.csv(\"../../_data/railroad_2012_clean_county.csv\")\n\n#Head\nhead(data)\n\n\n  state               county total_employees\n1    AE                  APO               2\n2    AK            ANCHORAGE               7\n3    AK FAIRBANKS NORTH STAR               2\n4    AK               JUNEAU               3\n5    AK    MATANUSKA-SUSITNA               2\n6    AK                SITKA               1\n\n#Tail\ntail(data)\n\n\n     state     county total_employees\n2925    WY   SHERIDAN             252\n2926    WY   SUBLETTE               3\n2927    WY SWEETWATER             196\n2928    WY      UINTA              49\n2929    WY   WASHAKIE              10\n2930    WY     WESTON              37\n\n#Dimensions\ndim(data)\n\n\n[1] 2930    3\n\n#Column Names\ncolnames(data)\n\n\n[1] \"state\"           \"county\"          \"total_employees\"\n\nHOMEWORK 3\nExperimenting with Data Transformation\nInitially I didn’t understand this data. I thought that running the count code by county would return to me the number of railroads in each county. Then I reread the description about what this dataset is and realized it’s not about number of railroads, just number of railroad employees and their geographic location. The code count(data,county) is actually particularly useless because all it does is return the number of times that a county name repeats itself across the country. For example, 12 different states have an “Adams County” that has Railroad employees.\nI’m keeping some of the less useful code here for practice, hopefully with an accurate description of what it actually is. I did not run count(data,county) since it takes up a lot of space.\n\n\n#count(data,county)\n\n#Count of Counties by State that have Railroad Employees\ncount(data,state)\n\n\n   state   n\n1     AE   1\n2     AK   6\n3     AL  67\n4     AP   1\n5     AR  72\n6     AZ  15\n7     CA  55\n8     CO  57\n9     CT   8\n10    DC   1\n11    DE   3\n12    FL  67\n13    GA 152\n14    HI   3\n15    IA  99\n16    ID  36\n17    IL 103\n18    IN  92\n19    KS  95\n20    KY 119\n21    LA  63\n22    MA  12\n23    MD  24\n24    ME  16\n25    MI  78\n26    MN  86\n27    MO 115\n28    MS  78\n29    MT  53\n30    NC  94\n31    ND  49\n32    NE  89\n33    NH  10\n34    NJ  21\n35    NM  29\n36    NV  12\n37    NY  61\n38    OH  88\n39    OK  73\n40    OR  33\n41    PA  65\n42    RI   5\n43    SC  46\n44    SD  52\n45    TN  91\n46    TX 221\n47    UT  25\n48    VA  92\n49    VT  14\n50    WA  39\n51    WI  69\n52    WV  53\n53    WY  22\n\n#Among Counties with Railroad Employees, what is the average number of employees in each county \nsummarise(data,avg=mean(total_employees))\n\n\n       avg\n1 87.17816\n\n#Among Counties with Railroad Employees, what is the average number of employees in each county that has railroad employees, by state\ndata %>%\n  group_by(state) %>%\n  summarise(avg=mean(total_employees))\n\n\n# A tibble: 53 × 2\n   state   avg\n   <chr> <dbl>\n 1 AE      2  \n 2 AK     17.2\n 3 AL     63.5\n 4 AP      1  \n 5 AR     53.8\n 6 AZ    210. \n 7 CA    239. \n 8 CO     64.0\n 9 CT    324  \n10 DC    279  \n# … with 43 more rows\n\nExperimenting with prop.table From this data I learned that just under 2% of railroad employees in the US (and the included Canadian county) are in Colorado.\n\n\n#Distribution of Railroad Employees across the US (%)\ndata%>%\n  select(state)%>%\n  table()%>%\n  prop.table()*100\n\n\n.\n        AE         AK         AL         AP         AR         AZ \n0.03412969 0.20477816 2.28668942 0.03412969 2.45733788 0.51194539 \n        CA         CO         CT         DC         DE         FL \n1.87713311 1.94539249 0.27303754 0.03412969 0.10238908 2.28668942 \n        GA         HI         IA         ID         IL         IN \n5.18771331 0.10238908 3.37883959 1.22866894 3.51535836 3.13993174 \n        KS         KY         LA         MA         MD         ME \n3.24232082 4.06143345 2.15017065 0.40955631 0.81911263 0.54607509 \n        MI         MN         MO         MS         MT         NC \n2.66211604 2.93515358 3.92491468 2.66211604 1.80887372 3.20819113 \n        ND         NE         NH         NJ         NM         NV \n1.67235495 3.03754266 0.34129693 0.71672355 0.98976109 0.40955631 \n        NY         OH         OK         OR         PA         RI \n2.08191126 3.00341297 2.49146758 1.12627986 2.21843003 0.17064846 \n        SC         SD         TN         TX         UT         VA \n1.56996587 1.77474403 3.10580205 7.54266212 0.85324232 3.13993174 \n        VT         WA         WI         WV         WY \n0.47781570 1.33105802 2.35494881 1.80887372 0.75085324 \n\nExperimenting with Filter and Arrange I created a subset of data that includes counties that have 1000 or more railroad employees. I named it large_railroadcounties. There are 27 counties with 1000 or more railroad employees.\n\n\n#Filter out counties that have 1000 or more railroad employees\nfilter(data, total_employees>=1000)\n\n\n   state           county total_employees\n1     CA      LOS ANGELES            2545\n2     CA        RIVERSIDE            1567\n3     CA   SAN BERNARDINO            2888\n4     CT        NEW HAVEN            1561\n5     DE       NEW CASTLE            1275\n6     FL            DUVAL            3073\n7     IL             COOK            8207\n8     IL             WILL            1784\n9     IN             LAKE            1999\n10    KS          JOHNSON            1286\n11    MO          JACKSON            2055\n12    NE        BOX BUTTE            1168\n13    NE          DOUGLAS            3797\n14    NE        LANCASTER            1619\n15    NE          LINCOLN            2289\n16    NJ            ESSEX            1097\n17    NY         DUTCHESS            1157\n18    NY           NASSAU            2076\n19    NY           QUEENS            1470\n20    NY          SUFFOLK            3685\n21    NY      WESTCHESTER            1040\n22    PA            BUCKS            1106\n23    PA     PHILADELPHIA            1649\n24    TX           HARRIS            2535\n25    TX          TARRANT            4235\n26    VA INDEPENDENT CITY            3249\n27    WA             KING            1039\n\n#Reassign large railroad counties\nlarge_railroadcounties<- filter(data,total_employees>=1000)\n\n#Head\nhead(large_railroadcounties)\n\n\n  state         county total_employees\n1    CA    LOS ANGELES            2545\n2    CA      RIVERSIDE            1567\n3    CA SAN BERNARDINO            2888\n4    CT      NEW HAVEN            1561\n5    DE     NEW CASTLE            1275\n6    FL          DUVAL            3073\n\n#Count\ncount(large_railroadcounties)\n\n\n   n\n1 27\n\n#Arrange by Total Employees \narrange(large_railroadcounties, desc(total_employees), state, county)\n\n\n   state           county total_employees\n1     IL             COOK            8207\n2     TX          TARRANT            4235\n3     NE          DOUGLAS            3797\n4     NY          SUFFOLK            3685\n5     VA INDEPENDENT CITY            3249\n6     FL            DUVAL            3073\n7     CA   SAN BERNARDINO            2888\n8     CA      LOS ANGELES            2545\n9     TX           HARRIS            2535\n10    NE          LINCOLN            2289\n11    NY           NASSAU            2076\n12    MO          JACKSON            2055\n13    IN             LAKE            1999\n14    IL             WILL            1784\n15    PA     PHILADELPHIA            1649\n16    NE        LANCASTER            1619\n17    CA        RIVERSIDE            1567\n18    CT        NEW HAVEN            1561\n19    NY           QUEENS            1470\n20    KS          JOHNSON            1286\n21    DE       NEW CASTLE            1275\n22    NE        BOX BUTTE            1168\n23    NY         DUTCHESS            1157\n24    PA            BUCKS            1106\n25    NJ            ESSEX            1097\n26    NY      WESTCHESTER            1040\n27    WA             KING            1039\n\nExperimenting with Select These are the counties and states in which there are 1000 or more railroad employees in 1 county.\n\n\nselect(large_railroadcounties,\"state\", \"county\")\n\n\n   state           county\n1     CA      LOS ANGELES\n2     CA        RIVERSIDE\n3     CA   SAN BERNARDINO\n4     CT        NEW HAVEN\n5     DE       NEW CASTLE\n6     FL            DUVAL\n7     IL             COOK\n8     IL             WILL\n9     IN             LAKE\n10    KS          JOHNSON\n11    MO          JACKSON\n12    NE        BOX BUTTE\n13    NE          DOUGLAS\n14    NE        LANCASTER\n15    NE          LINCOLN\n16    NJ            ESSEX\n17    NY         DUTCHESS\n18    NY           NASSAU\n19    NY           QUEENS\n20    NY          SUFFOLK\n21    NY      WESTCHESTER\n22    PA            BUCKS\n23    PA     PHILADELPHIA\n24    TX           HARRIS\n25    TX          TARRANT\n26    VA INDEPENDENT CITY\n27    WA             KING\n\nExperimenting with Filter, Vector, Piping, and Group by\n\n\n#Created subset of data that is just New England states, rename that group \"new_england\"\nnew_england <- filter(data, state %in% c(\"NH\", \"VT\", \"CT\", \"MA\", \"RI\", \"ME\"))\n\n#Among New England Counties with Railroad Employees, what is the average number of employees in each county \nsummarise(new_england, avg=mean(total_employees))\n\n\n       avg\n1 119.4462\n\n#Count of New England Counties by State that have Railroad Employees\ncount(new_england,state)\n\n\n  state  n\n1    CT  8\n2    MA 12\n3    ME 16\n4    NH 10\n5    RI  5\n6    VT 14\n\n#Among New England Counties with Railroad Employees, what is the average number of employees in each county that has railroad employees, by state\nnew_england %>%\n  group_by(state) %>%\n  summarise(avg=mean(total_employees))\n\n\n# A tibble: 6 × 2\n  state   avg\n  <chr> <dbl>\n1 CT    324  \n2 MA    282. \n3 ME     40.9\n4 NH     39.3\n5 RI     97.4\n6 VT     18.5\n\nExperimenting with Advanced Functions Working with Renaming and Pivot_longer. I want to get more familiar with pivot longer, but I don’t think there are enough variables in this dataset to really experiment with it.\n\n\n#rename\ndata<-rename(data,employees = total_employees)\ncolnames(data)\n\n\n[1] \"state\"     \"county\"    \"employees\"\n\n#new_england<-rename(new_england,employees = total_employees)\ncolnames(new_england)\n\n\n[1] \"state\"           \"county\"          \"total_employees\"\n\n#relocate()\n\n#across()/c_across()\n\n#pivot_longer()/pivot_wider()\n#results are lengthy and not useful\n#data%>%\n  #pivot_longer(cols=employees,\n               #names_to=\"Type\",\n               #values_to=\"numberemployees\")\n            \n#purrr::map()\n\n#lapply()\n\n\n\nExperimenting with Advanced Functions Cont.\n\n\n#case_when()\n#Assign the words Large, medium and small to specific numeric values for number of employees\ndata<-data%>%\n  mutate(Railroad_size = case_when(\n         employees >= 1000 ~ \"Large\",\n         employees >= 500 & employees < 1000 ~ \"Medium\",\n         employees < 500 ~ \"Small\"))\n\n#See how many counties from full dataset have a small, medium and large amount of railroad employees\ntable(select(data, Railroad_size))\n\n\n\n Large Medium  Small \n    27     65   2838 \n\n#See how many counties in New England have a small, medium or large amount of railroad employees\nnew_england<-new_england%>%\n  mutate(Railroad_size = case_when(\n         total_employees >= 1000 ~ \"Large\",\n         total_employees >= 500 & total_employees < 1000 ~ \"Medium\",\n         total_employees < 500 ~ \"Small\"))\n\ntable(select(new_england, Railroad_size))\n\n\n\n Large Medium  Small \n     1      2     62 \n\n#Use crosstabs to which new england state have counties with a small, medium and large amount of railroad employees\nxtabs(~state+ Railroad_size,new_england)\n\n\n     Railroad_size\nstate Large Medium Small\n   CT     1      0     7\n   MA     0      2    10\n   ME     0      0    16\n   NH     0      0    10\n   RI     0      0     5\n   VT     0      0    14\n\nExperimenting with ggplot, boxplot, labels Connecticut has an outlier. Connecticut has 1 county with an especially large number of railroad employees.\n\n\n#Boxplot for New England State Counties\nggplot(new_england,aes(state,total_employees))+geom_boxplot()+\nlabs(title = \"Railroad Employee County Counts by State, NE\", y = \"Total Employees\", x = \"State\") \n\n\n\n\nSame data, just shown differently\n\n\n#Geompoints for New England State Counties\nggplot(new_england,aes(state,total_employees))+\n  geom_point()+\n  geom_smooth()+\n  labs(title = \"Railroad Employee County Counts by State, NE\", y = \"Total Employees\", x = \"State\") \n\n\n\n\nExperimenting with ggplot and fill\nI would love to use fill, but it doesn’t make sense for this dataset. It doesn’t make sense because my third variable (county) is basically different for every state. This would be much more useful if that variable was something that had valuables that were applicable to all states.\n\n\n#Geomplot for New England States with County filled (Two Ways)\n#ggplot(new_england,aes(state, fill=county))+ geom_bar()+\n  #theme_bw()+\n  #labs(title=\"New England States Railroad Employee Counts by State and County\", y=\"Number of Employees\", x= \"State\")\n\n#ggplot(data=new_england)+\n  #geom_bar(mapping=aes(x=state, fill=county))\n  #theme_bw()+\n  #labs(title=\"New England States Railroad Employee Counts by State and County\", y=\"Number of Employees\", x= \"State\")\n\n\n\nExperimenting with geompoint, with different dataset\nIllinois has 1 county that has over 8000 railroad employees\n\n\nggplot(data=large_railroadcounties)+\n  geom_point(mapping=aes(x=state, y=total_employees))+\n  labs(title = \"States with counties with 1000+ Railroad Employees\", y = \"Total Employees\", x = \"State\") \n\n\n\n\n\nSaving this code shared by Larri\n#blackturnout <- blackturnout %>%\n  #mutate(candidateRename = recode(candidate, `1` = \"co-ethnic\", `0` = \"not co-ethnic\"))\n\n\n\nDistill is a publication format for scientific and technical writing, native to the web.\n\nLearn more about using Distill at <https://rstudio.github.io/distill>.\n\n\n\n\n```{.r .distill-force-highlighting-css}\n\n\n",
    "preview": "posts/2021-08-17-railroad-county-tracy/railroad-county-tracy_files/figure-html5/unnamed-chunk-9-1.png",
    "last_modified": "2021-08-20T15:46:18-04:00",
    "input_file": "railroad-county-tracy.knit.md",
    "preview_width": 960,
    "preview_height": 320
  },
  {
    "path": "posts/2021-08-18-ankithw2/",
    "title": "Ankit_HW2",
    "description": "A short description of the IRIS dataset.",
    "author": [
      {
        "name": "Ankit Kumar",
        "url": {}
      }
    ],
    "date": "2021-08-18",
    "categories": [],
    "contents": "\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\" \n[5] \"Species\"     \n\n\n\n\n\n\n\n",
    "preview": "posts/2021-08-18-ankithw2/ankithw2_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2021-08-20T15:46:20-04:00",
    "input_file": "ankithw2.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-08-18-interest-rate-inflation-and-unemployment-rates/",
    "title": "Interest Rate, Inflation, and Unemployment rates",
    "description": "A comparison of interest rates vs GDP change vs inflation vs unemployment rates in the US from 1954 - 2017",
    "author": [
      {
        "name": "Ben Lewis",
        "url": {}
      }
    ],
    "date": "2021-08-18",
    "categories": [],
    "contents": "\nReading in my data.\nThis set contains monthly Federal Reserve interest rates from 1954-2017. It also contains the quarterly inflation rates, and monthly unemployment rates. I downloaded this data from Kaggle. Raw data can be found here\n\n\nfed_rates <- read_csv(\"../../_data/FedFundsRate.csv\")\n\n\n\nFixing dates\nChanging numeric values in column “Year” to names of the month. I want to simplify the data set by being able to see the names of the month instead of month number.\n\n\nfed_rates <- fed_rates %>%\n  mutate(Month = case_when(\n         Month == 1 ~ \"January\",\n         Month == 2 ~ \"February\",\n         Month == 3 ~ \"March\",\n         Month == 4 ~ \"April\",\n         Month == 5 ~ \"May\",\n         Month == 6 ~ \"June\",\n         Month == 7 ~ \"July\",\n         Month == 8 ~ \"August\", \n         Month == 9 ~ \"September\",\n         Month == 10 ~ \"October\",\n         Month == 11 ~ \"November\",\n         Month == 12 ~ \"December\")\n  )\n\n\n\nRemove variables\nThere are variables in the fed_rates data set that I am not concerned with. These columns are the Fed Funds Target Rate, Fed Funds Upper Target Rate, and Fed Funds Lower Target Rate. Taking my variables from 10 to 7 by removing those columns and reducing noise in the data.\n\n\nfed_rates_new <- fed_rates %>%\n  select(\"Year\" , \"Month\" ,  \"Day\" , \"Effective Federal Funds Rate\" ,  \"Real GDP (Percent Change)\",  \"Unemployment Rate\" ,  \"Inflation Rate\")\n\nfed_rates_new\n\n\n# A tibble: 904 × 7\n    Year Month       Day `Effective Federal Fun… `Real GDP (Percent C…\n   <dbl> <chr>     <dbl>                   <dbl>                 <dbl>\n 1  1954 July          1                    0.8                    4.6\n 2  1954 August        1                    1.22                  NA  \n 3  1954 September     1                    1.06                  NA  \n 4  1954 October       1                    0.85                   8  \n 5  1954 November      1                    0.83                  NA  \n 6  1954 December      1                    1.28                  NA  \n 7  1955 January       1                    1.39                  11.9\n 8  1955 February      1                    1.29                  NA  \n 9  1955 March         1                    1.35                  NA  \n10  1955 April         1                    1.43                   6.7\n# … with 894 more rows, and 2 more variables:\n#   Unemployment Rate <dbl>, Inflation Rate <dbl>\n\nFiltering by Quarter\nto make viewing quarterly GDP growth rate data easier to track. Because we do not tend to see wild swings in monthly data in regards to inflation and interest rate change.\n\n\nfed_rates_quarter <- fed_rates_new %>%\n  filter(`Month` %in% c(\"January\" , \"April\" , \"July\" , \"October\"))\n\nfed_rates_quarter\n\n\n# A tibble: 295 × 7\n    Year Month     Day `Effective Federal Funds Rate` `Real GDP (Perc…\n   <dbl> <chr>   <dbl>                          <dbl>            <dbl>\n 1  1954 July        1                           0.8               4.6\n 2  1954 October     1                           0.85              8  \n 3  1955 January     1                           1.39             11.9\n 4  1955 April       1                           1.43              6.7\n 5  1955 July        1                           1.68              5.5\n 6  1955 October     1                           2.24              2.4\n 7  1956 January     1                           2.45             -1.5\n 8  1956 April       1                           2.62              3.4\n 9  1956 July        1                           2.75             -0.3\n10  1956 October     1                           2.96              6.7\n# … with 285 more rows, and 2 more variables:\n#   Unemployment Rate <dbl>, Inflation Rate <dbl>\n\nReal GDP (Percent Change) over time\nWe see a downward annual trend since 1954 with fairly substantial movement in GDP percent growth quarterly. The highest % change in GDP came in Q2 (April) of 1978 with a 16% increase QoQ.\n\n\nsummarise_GDP <- fed_rates_quarter \nselect(fed_rates_quarter,`Month`, `Real GDP (Percent Change)`)\n\n\n# A tibble: 295 × 2\n   Month   `Real GDP (Percent Change)`\n   <chr>                         <dbl>\n 1 July                            4.6\n 2 October                         8  \n 3 January                        11.9\n 4 April                           6.7\n 5 July                            5.5\n 6 October                         2.4\n 7 January                        -1.5\n 8 April                           3.4\n 9 July                           -0.3\n10 October                         6.7\n# … with 285 more rows\n\n  summarise(fed_rates_quarter , mean.Real_GDP = mean(`Real GDP (Percent Change)` , na.rm = TRUE) , max.Real_GDP = max(`Real GDP (Percent Change)` , na.rm = TRUE) , min.Real_GDP = min(`Real GDP (Percent Change)` , na.rm = TRUE) , sd.Real_GDP = sd(`Real GDP (Percent Change)` , na.rm = TRUE) , IQR.Real_GDP = IQR(`Real GDP (Percent Change)` , na.rm = TRUE))\n\n\n# A tibble: 1 × 5\n  mean.Real_GDP max.Real_GDP min.Real_GDP sd.Real_GDP IQR.Real_GDP\n          <dbl>        <dbl>        <dbl>       <dbl>        <dbl>\n1          3.14         16.5          -10        3.60         3.48\n\n\n\nggplot(fed_rates_quarter, aes(`Year` , `Real GDP (Percent Change)`)) + \n  geom_point() + \n  geom_smooth()\n\n\n\n\nUnemployment rate over time\n\n\nggplot(fed_rates_quarter, aes(`Year` , `Unemployment Rate`)) + \n  geom_point() + \n  geom_smooth() \n\n\n\n\nInterest Rate over time\n\n\nggplot(fed_rates_quarter, aes(`Year` , `Effective Federal Funds Rate`)) + \n  geom_point() + \n  geom_smooth()\n\n\n\n\nInflation Rate over time\n\n\n ggplot(fed_rates_quarter, aes(`Year` , `Inflation Rate`)) + \n  geom_point() + \n  geom_smooth()\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-08-18-interest-rate-inflation-and-unemployment-rates/interest-rate-inflation-and-unemployment-rates_files/figure-html5/unnamed-chunk-6-1.png",
    "last_modified": "2021-08-20T15:46:24-04:00",
    "input_file": "interest-rate-inflation-and-unemployment-rates.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-08-18-reading-in-tabular-data/",
    "title": "Reading in Tabular Data",
    "description": "Two examples of reading in Excel Tables with\nthe advanced data sets.",
    "author": [
      {
        "name": "Meredith Rolfe",
        "url": {}
      }
    ],
    "date": "2021-08-18",
    "categories": [
      "example code",
      "data cleaning"
    ],
    "contents": "\nThis post will take a closer look at some tools that can be used to read in tabular data (i.e., tables) that are often published based on government sources or by other organizations. Tabular data is often made available in Excel format (.xls or .xlsx) and is formatted for ease of reading - but this can make it tricky to read into R and reshape into a usable dataset.\nReading in tabular data will follow the same general work flow or work process regardless of formatting differences. We will work through the steps in detail below, but here is an overview. Note that not every step is needed for every file.\nIdentify grouping variables and values to extract from the table\nIdentify formatting issues that need to be addressed or eliminated\nColumn issues usually addressed during data read-in\nRow issues usually addressed using filter (and stringr package)\nCreate or mutate new variables as required, using separate, pivot_longer`, etc\nRailroad data\nThe railroad data set is a fairly straightforward formatted table published by the Railroad Retirement Board. The value variable is a count of the number of employees in each county and state combination.\n Looking at the excel file, we can see that there are only a few issues: 1. There are three rows at the top of the sheet that are not needed 2. There are blank columns that are not needed. 3. There are Total rows for each state that are not needed\nSkipping title rows\nFor the first issue, we use the “skip” option on read_excel from the readxl package to skip the rows at the top.\n\n\nread_excel(\"../../_data/StateCounty2012.xls\",\n                     skip = 3)\n\n\n# A tibble: 2,990 × 5\n   STATE     ...2  COUNTY               ...4  TOTAL\n   <chr>     <lgl> <chr>                <lgl> <dbl>\n 1 AE        NA    APO                  NA        2\n 2 AE Total1 NA    <NA>                 NA        2\n 3 AK        NA    ANCHORAGE            NA        7\n 4 AK        NA    FAIRBANKS NORTH STAR NA        2\n 5 AK        NA    JUNEAU               NA        3\n 6 AK        NA    MATANUSKA-SUSITNA    NA        2\n 7 AK        NA    SITKA                NA        1\n 8 AK        NA    SKAGWAY MUNICIPALITY NA       88\n 9 AK Total  NA    <NA>                 NA      103\n10 AL        NA    AUTAUGA              NA      102\n# … with 2,980 more rows\n\nRemoving empty columns\nFor the second issue, I name the blank columns “delete” to make is easy to remove the unwanted columns. I then use select (with the ! sign to designate the complement or NOT) to select columns we wish to keep in the dataset - the rest are removed. Note that I skip 4 rows this time as I do not need the original header row.\nThere are other approaches you could use for this task (e.g., remove all columns that have no valid volues), but hard coding of variable names and types during data read in is not considered a violation of best practices and - if used strategically - can often make later data cleaning much easier.\n\n\nread_excel(\"../../_data/StateCounty2012.xls\",\n                     skip = 4,\n                     col_names= c(\"State\", \"delete\", \"County\", \"delete\", \"Employees\"))%>%\n  select(!contains(\"delete\"))\n\n\n# A tibble: 2,990 × 3\n   State     County               Employees\n   <chr>     <chr>                    <dbl>\n 1 AE        APO                          2\n 2 AE Total1 <NA>                         2\n 3 AK        ANCHORAGE                    7\n 4 AK        FAIRBANKS NORTH STAR         2\n 5 AK        JUNEAU                       3\n 6 AK        MATANUSKA-SUSITNA            2\n 7 AK        SITKA                        1\n 8 AK        SKAGWAY MUNICIPALITY        88\n 9 AK Total  <NA>                       103\n10 AL        AUTAUGA                    102\n# … with 2,980 more rows\n\nFiltering “total” rows\nFor the third issue, we are going to use filter to identify (and drop the rows that have the word “Total” in the State column). str_detect can be used to find specific rows within a column that have the designated “pattern”, while the “!” designates the complement of the selected rows (i.e., those without the “pattern” we are searching for.)\nThe str_detect command is from the stringr package, and is a powerful and easy to use implementation of grep and regex in the tidyverse - the base R functions (grep, gsub, etc) are classic but far more difficult to use, particularly for those not in practice. Be sure to explore the stringr package on your own.\n\n\nrailroad<-read_excel(\"../../_data/StateCounty2012.xls\",\n                     skip = 4,\n                     col_names= c(\"State\", \"delete\", \"County\", \"delete\", \"Employees\"))%>%\n  select(!contains(\"delete\"))%>%\n  filter(!str_detect(State, \"Total\"))\nrailroad\n\n\n# A tibble: 2,933 × 3\n   State County               Employees\n   <chr> <chr>                    <dbl>\n 1 AE    APO                          2\n 2 AK    ANCHORAGE                    7\n 3 AK    FAIRBANKS NORTH STAR         2\n 4 AK    JUNEAU                       3\n 5 AK    MATANUSKA-SUSITNA            2\n 6 AK    SITKA                        1\n 7 AK    SKAGWAY MUNICIPALITY        88\n 8 AL    AUTAUGA                    102\n 9 AL    BALDWIN                    143\n10 AL    BARBOUR                      1\n# … with 2,923 more rows\n\nRemove any table notes\nTables often have notes in the last few table rows. You can check table limits and use this information during data read-in to not read the notes by setting the n-max option at the total number of rows to read, or less commonly, the range option to specify the spreadsheet range in standard excel naming (e.g., “B4:R142”). If you didn’t handle this on read in, you can use the tail command to check for notes and either tail or head to keep only the rows that you need.\n\n\ntail(railroad, 10)\n\n\n# A tibble: 10 × 3\n   State                                               County Employees\n   <chr>                                               <chr>      <dbl>\n 1 WY                                                  PLATTE       129\n 2 WY                                                  SHERI…       252\n 3 WY                                                  SUBLE…         3\n 4 WY                                                  SWEET…       196\n 5 WY                                                  UINTA         49\n 6 WY                                                  WASHA…        10\n 7 WY                                                  WESTON        37\n 8 CANADA                                              <NA>         662\n 9 1  Military designation.                            <NA>          NA\n10 NOTE:  Excludes 2,896 employees without an address. <NA>          NA\n\n#remove the last two observations\nrailroad <-head(railroad, -2)\n\ntail(railroad, 10)\n\n\n# A tibble: 10 × 3\n   State  County     Employees\n   <chr>  <chr>          <dbl>\n 1 WY     NIOBRARA          51\n 2 WY     PARK              29\n 3 WY     PLATTE           129\n 4 WY     SHERIDAN         252\n 5 WY     SUBLETTE           3\n 6 WY     SWEETWATER       196\n 7 WY     UINTA             49\n 8 WY     WASHAKIE          10\n 9 WY     WESTON            37\n10 CANADA <NA>             662\n\nRegenerating grouped totals\nAnd that is all it takes! The data are now ready for analysis. For example, suppose we wished to recover the information about state totals. This is easy to do using group_by.\n\n\nrailroad%>%\n  group_by(State)%>%\n  summarise(`State Employees` = sum(Employees))\n\n\n# A tibble: 54 × 2\n   State  `State Employees`\n   <chr>              <dbl>\n 1 AE                     2\n 2 AK                   103\n 3 AL                  4257\n 4 AP                     1\n 5 AR                  3871\n 6 AZ                  3153\n 7 CA                 13137\n 8 CANADA               662\n 9 CO                  3650\n10 CT                  2592\n# … with 44 more rows\n\nAustralian Marriage Data\nThis is another government published tabular data source. In 2017, Australia conducted a postal survey to gauge citizens’ opinions towards same sex marriage. The survey questions was straightforward: “Should the law be changed to allow same-sex couples to marry?” Here is a quick image showing the original table format.\n While similar in some respect to the State Railroad data above, the Australian survey data are clearly more complex in several respects. - There are two values (vote count and percentage) in the dataset - The values appear to be redundent (percentage is easy to recover from vote count data) - There may be other redundant information in - Grouped information instead of individual observations where variables appear elsewhere - Redundent vvariables (Total:Response Clear on the left and ResponeClear)\nIdentify desired data structure\nIf we decide to temporarily ignore the proportions data (as suggested above) and the “totals” columns, we can identify four potentially distinct pieces of information in addition to the vote count columns: County, Division, response(yes, no, response unclear, and non-responding) and vote count. Our goal is to create this desirable data set.\nRepeating steps from above\nWe will once again use skip and col_names to read in the data, select to get rid of unneeded columns, and filter to get rid of unneeded rows. We also use the drop_na function to filter unwanted rows.\n\n\nvotes <- read_excel(\"../../_data/australian_marriage_law_postal_survey_2017_-_response_final.xls\",\n           sheet=\"Table 2\",\n           skip=7,\n           col_names = c(\"Town\", \"Yes\", \"d\", \"No\", rep(\"d\", 6), \"Illegible\", \"d\", \"No Response\", rep(\"d\", 3)))%>%\n  select(!starts_with(\"d\"))%>%\n  drop_na(Town)%>%\n  filter(!str_detect(Town, \"(Total)\"))%>%\n  filter(!str_starts(Town, \"\\\\(\"))\n\nvotes\n\n\n# A tibble: 160 × 5\n   Town                        Yes    No Illegible `No Response`\n   <chr>                     <dbl> <dbl>     <dbl>         <dbl>\n 1 New South Wales Divisions    NA    NA        NA            NA\n 2 Banks                     37736 46343       247         20928\n 3 Barton                    37153 47984       226         24008\n 4 Bennelong                 42943 43215       244         19973\n 5 Berowra                   48471 40369       212         16038\n 6 Blaxland                  20406 57926       220         25883\n 7 Bradfield                 53681 34927       202         17261\n 8 Calare                    54091 35779       285         25342\n 9 Chifley                   32871 46702       263         28180\n10 Cook                      47505 38804       229         18713\n# … with 150 more rows\n\nAt this point, you can see we are REALLY close. We have yes and no variable plus illegible and no response. That said, tthe current step is more complicated. Each observation (county) needs a variable for administrative “division”, but this is displayed at the top of each block.\nThe following code uses case_when to make a new “Divisions” variables with an entry (e.g., New South Wales Division) where there is a Division name in the town column, and otherwise create just an empty space.\nAt that point, the following loop (with seq_along) can be used to fill in empty spaces with the most recent Divisions name, and then filter out rows with only the title information.\n\n\nvotes<- votes%>%\n  mutate(Divisions = case_when(\n    str_ends(Town, \"Divisions\") ~ Town,\n    TRUE ~ NA_character_\n  ))\n\nfor(i in seq_along(votes$Divisions)){\n  votes$Divisions[i]<-ifelse(is.na(votes$Divisions[i]),votes$Divisions[i-1], votes$Divisions[i])\n}\n\nvotes<- filter(votes,!str_detect(Town, \"Divisions|Australia\"))\nvotes\n\n\n# A tibble: 150 × 6\n   Town        Yes    No Illegible `No Response` Divisions            \n   <chr>     <dbl> <dbl>     <dbl>         <dbl> <chr>                \n 1 Banks     37736 46343       247         20928 New South Wales Divi…\n 2 Barton    37153 47984       226         24008 New South Wales Divi…\n 3 Bennelong 42943 43215       244         19973 New South Wales Divi…\n 4 Berowra   48471 40369       212         16038 New South Wales Divi…\n 5 Blaxland  20406 57926       220         25883 New South Wales Divi…\n 6 Bradfield 53681 34927       202         17261 New South Wales Divi…\n 7 Calare    54091 35779       285         25342 New South Wales Divi…\n 8 Chifley   32871 46702       263         28180 New South Wales Divi…\n 9 Cook      47505 38804       229         18713 New South Wales Divi…\n10 Cowper    57493 38317       315         25197 New South Wales Divi…\n# … with 140 more rows\n\nPivot_longer to recover structure\nSupposed we wanted to create a stacked bar chart to compare the % who votes Yes to the people who either said No or didn’t vote. The easiest way is to pivot longer into the original data format: State, Division, surveyResponse, count.\n\n\nvotes%>%\n  pivot_longer(\n    cols = Yes:`No Response`,\n    names_to = \"Response\",\n    values_to = \"Count\"\n  )\n\n\n# A tibble: 600 × 4\n   Town      Divisions                 Response    Count\n   <chr>     <chr>                     <chr>       <dbl>\n 1 Banks     New South Wales Divisions Yes         37736\n 2 Banks     New South Wales Divisions No          46343\n 3 Banks     New South Wales Divisions Illegible     247\n 4 Banks     New South Wales Divisions No Response 20928\n 5 Barton    New South Wales Divisions Yes         37153\n 6 Barton    New South Wales Divisions No          47984\n 7 Barton    New South Wales Divisions Illegible     226\n 8 Barton    New South Wales Divisions No Response 24008\n 9 Bennelong New South Wales Divisions Yes         42943\n10 Bennelong New South Wales Divisions No          43215\n# … with 590 more rows\n\nSpecial thanks to Karl, Shih-Yen, Mohit, and the other students in the advanced group for allowing me to use their blog submissions as a starting point for this demonstration!\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:46:27-04:00",
    "input_file": "reading-in-tabular-data.knit.md"
  },
  {
    "path": "posts/2021-08-18-sathvikhotelbookingsdatahw3/",
    "title": "sathvik_hotel_bookings_data_hw3",
    "description": "Hotel bookings Data",
    "author": [
      {
        "name": "sathvik_thogaru",
        "url": {}
      }
    ],
    "date": "2021-08-18",
    "categories": [],
    "contents": "\nImporting data\nThis data set contains a single file which compares various booking information between hotels.\n\n\nlibrary(skimr)\nlibrary(lubridate)\nlibrary(tidyverse)\n\n\n\n\n\nhotel_bookings <- read_csv(\"../../_data/hotel_bookings.csv\")\nhead(hotel_bookings)\n\n\n# A tibble: 6 × 32\n  hotel        is_canceled lead_time arrival_date_ye… arrival_date_mo…\n  <chr>              <dbl>     <dbl>            <dbl> <chr>           \n1 Resort Hotel           0       342             2015 July            \n2 Resort Hotel           0       737             2015 July            \n3 Resort Hotel           0         7             2015 July            \n4 Resort Hotel           0        13             2015 July            \n5 Resort Hotel           0        14             2015 July            \n6 Resort Hotel           0        14             2015 July            \n# … with 27 more variables: arrival_date_week_number <dbl>,\n#   arrival_date_day_of_month <dbl>, stays_in_weekend_nights <dbl>,\n#   stays_in_week_nights <dbl>, adults <dbl>, children <dbl>,\n#   babies <dbl>, meal <chr>, country <chr>, market_segment <chr>,\n#   distribution_channel <chr>, is_repeated_guest <dbl>,\n#   previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>, …\n\nskim() is an alternative to summary(), quickly providing a broad overview of a data frame. It handles data of all types, dispatching a different set of summary functions based on the types of columns in the data frame.\n\n\nskim(hotel_bookings)\n\n\nTable 1: Data summary\nName\nhotel_bookings\nNumber of rows\n119390\nNumber of columns\n32\n_______________________\n\nColumn type frequency:\n\ncharacter\n13\nDate\n1\nnumeric\n18\n________________________\n\nGroup variables\nNone\nVariable type: character\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\nhotel\n0\n1\n10\n12\n0\n2\n0\narrival_date_month\n0\n1\n3\n9\n0\n12\n0\nmeal\n0\n1\n2\n9\n0\n5\n0\ncountry\n0\n1\n2\n4\n0\n178\n0\nmarket_segment\n0\n1\n6\n13\n0\n8\n0\ndistribution_channel\n0\n1\n3\n9\n0\n5\n0\nreserved_room_type\n0\n1\n1\n1\n0\n10\n0\nassigned_room_type\n0\n1\n1\n1\n0\n12\n0\ndeposit_type\n0\n1\n10\n10\n0\n3\n0\nagent\n0\n1\n1\n4\n0\n334\n0\ncompany\n0\n1\n1\n4\n0\n353\n0\ncustomer_type\n0\n1\n5\n15\n0\n4\n0\nreservation_status\n0\n1\n7\n9\n0\n3\n0\nVariable type: Date\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\nreservation_status_date\n0\n1\n2014-10-17\n2017-09-14\n2016-08-07\n926\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nis_canceled\n0\n1\n0.37\n0.48\n0.00\n0.00\n0.00\n1\n1\n▇▁▁▁▅\nlead_time\n0\n1\n104.01\n106.86\n0.00\n18.00\n69.00\n160\n737\n▇▂▁▁▁\narrival_date_year\n0\n1\n2016.16\n0.71\n2015.00\n2016.00\n2016.00\n2017\n2017\n▃▁▇▁▆\narrival_date_week_number\n0\n1\n27.17\n13.61\n1.00\n16.00\n28.00\n38\n53\n▅▇▇▇▅\narrival_date_day_of_month\n0\n1\n15.80\n8.78\n1.00\n8.00\n16.00\n23\n31\n▇▇▇▇▆\nstays_in_weekend_nights\n0\n1\n0.93\n1.00\n0.00\n0.00\n1.00\n2\n19\n▇▁▁▁▁\nstays_in_week_nights\n0\n1\n2.50\n1.91\n0.00\n1.00\n2.00\n3\n50\n▇▁▁▁▁\nadults\n0\n1\n1.86\n0.58\n0.00\n2.00\n2.00\n2\n55\n▇▁▁▁▁\nchildren\n4\n1\n0.10\n0.40\n0.00\n0.00\n0.00\n0\n10\n▇▁▁▁▁\nbabies\n0\n1\n0.01\n0.10\n0.00\n0.00\n0.00\n0\n10\n▇▁▁▁▁\nis_repeated_guest\n0\n1\n0.03\n0.18\n0.00\n0.00\n0.00\n0\n1\n▇▁▁▁▁\nprevious_cancellations\n0\n1\n0.09\n0.84\n0.00\n0.00\n0.00\n0\n26\n▇▁▁▁▁\nprevious_bookings_not_canceled\n0\n1\n0.14\n1.50\n0.00\n0.00\n0.00\n0\n72\n▇▁▁▁▁\nbooking_changes\n0\n1\n0.22\n0.65\n0.00\n0.00\n0.00\n0\n21\n▇▁▁▁▁\ndays_in_waiting_list\n0\n1\n2.32\n17.59\n0.00\n0.00\n0.00\n0\n391\n▇▁▁▁▁\nadr\n0\n1\n101.83\n50.54\n-6.38\n69.29\n94.58\n126\n5400\n▇▁▁▁▁\nrequired_car_parking_spaces\n0\n1\n0.06\n0.25\n0.00\n0.00\n0.00\n0\n8\n▇▁▁▁▁\ntotal_of_special_requests\n0\n1\n0.57\n0.79\n0.00\n0.00\n0.00\n1\n5\n▇▁▁▁▁\n\nData Wrangling\ntidying the data\nfinding the na values in the dataframe( row and column) using which()\n\n\nwhich(is.na(hotel_bookings), arr.ind=TRUE)\n\n\n       row col\n[1,] 40601  11\n[2,] 40668  11\n[3,] 40680  11\n[4,] 41161  11\n\n\n\nhotel_bookings[c(40601,40668,40680,41161),]\n\n\n# A tibble: 4 × 32\n  hotel      is_canceled lead_time arrival_date_year arrival_date_mon…\n  <chr>            <dbl>     <dbl>             <dbl> <chr>            \n1 City Hotel           1         2              2015 August           \n2 City Hotel           1         1              2015 August           \n3 City Hotel           1         1              2015 August           \n4 City Hotel           1         8              2015 August           \n# … with 27 more variables: arrival_date_week_number <dbl>,\n#   arrival_date_day_of_month <dbl>, stays_in_weekend_nights <dbl>,\n#   stays_in_week_nights <dbl>, adults <dbl>, children <dbl>,\n#   babies <dbl>, meal <chr>, country <chr>, market_segment <chr>,\n#   distribution_channel <chr>, is_repeated_guest <dbl>,\n#   previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>, …\n\n\n\nhotel_bookings <- filter(hotel_bookings, !is.na(children)) \n\n\n\n\n\nsum(is.na(hotel_bookings))\n\n\n[1] 0\n\ntransforming data and visualizing\n\n\n(hotel_bookings<-hotel_bookings %>% \n  mutate(arrival_month = recode(arrival_date_month,\"January\"=1,\"February\"=2,\"March\"=3,\"April\"=4,\"May\"=5,\"June\"=6,\"July\"=7,\"August\"=8,\"September\"=9,\"October\"=10,\"November\"=11,\"December\"=12)))\n\n\n# A tibble: 119,386 × 33\n   hotel        is_canceled lead_time arrival_date_ye… arrival_date_mo…\n   <chr>              <dbl>     <dbl>            <dbl> <chr>           \n 1 Resort Hotel           0       342             2015 July            \n 2 Resort Hotel           0       737             2015 July            \n 3 Resort Hotel           0         7             2015 July            \n 4 Resort Hotel           0        13             2015 July            \n 5 Resort Hotel           0        14             2015 July            \n 6 Resort Hotel           0        14             2015 July            \n 7 Resort Hotel           0         0             2015 July            \n 8 Resort Hotel           0         9             2015 July            \n 9 Resort Hotel           1        85             2015 July            \n10 Resort Hotel           1        75             2015 July            \n# … with 119,376 more rows, and 28 more variables:\n#   arrival_date_week_number <dbl>, arrival_date_day_of_month <dbl>,\n#   stays_in_weekend_nights <dbl>, stays_in_week_nights <dbl>,\n#   adults <dbl>, children <dbl>, babies <dbl>, meal <chr>,\n#   country <chr>, market_segment <chr>, distribution_channel <chr>,\n#   is_repeated_guest <dbl>, previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>, …\n\n\n\n(hotel_bookings <- hotel_bookings%>%\n  mutate(arrival_date = make_date(arrival_date_year,arrival_month,arrival_date_day_of_month)))\n\n\n# A tibble: 119,386 × 34\n   hotel        is_canceled lead_time arrival_date_ye… arrival_date_mo…\n   <chr>              <dbl>     <dbl>            <dbl> <chr>           \n 1 Resort Hotel           0       342             2015 July            \n 2 Resort Hotel           0       737             2015 July            \n 3 Resort Hotel           0         7             2015 July            \n 4 Resort Hotel           0        13             2015 July            \n 5 Resort Hotel           0        14             2015 July            \n 6 Resort Hotel           0        14             2015 July            \n 7 Resort Hotel           0         0             2015 July            \n 8 Resort Hotel           0         9             2015 July            \n 9 Resort Hotel           1        85             2015 July            \n10 Resort Hotel           1        75             2015 July            \n# … with 119,376 more rows, and 29 more variables:\n#   arrival_date_week_number <dbl>, arrival_date_day_of_month <dbl>,\n#   stays_in_weekend_nights <dbl>, stays_in_week_nights <dbl>,\n#   adults <dbl>, children <dbl>, babies <dbl>, meal <chr>,\n#   country <chr>, market_segment <chr>, distribution_channel <chr>,\n#   is_repeated_guest <dbl>, previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>, …\n\nlooking for type of hotels booked by guests\n\n\n(hotels_info<-data.frame(table(hotel_bookings$hotel)))\n\n\n          Var1  Freq\n1   City Hotel 79326\n2 Resort Hotel 40060\n\n\n\npie(hotels_info$Freq, labels=paste(hotels_info$Var1,sep = \"=\", hotels_info$Freq), main = \"type of hotels booked by guests\")\n\n\n\n\nwhere do most of the guests come from?\n\n\n(guests_country_details <- hotel_bookings %>% \n   group_by(country) %>% \n   count() %>% \n   ungroup() %>% \n   arrange(desc(n)))\n\n\n# A tibble: 178 × 2\n   country     n\n   <chr>   <int>\n 1 PRT     48586\n 2 GBR     12129\n 3 FRA     10415\n 4 ESP      8568\n 5 DEU      7287\n 6 ITA      3766\n 7 IRL      3375\n 8 BEL      2342\n 9 BRA      2224\n10 NLD      2104\n# … with 168 more rows\n\nmost guests by top country’s\n\n\nggplot(filter(guests_country_details, n>1500))+\n  geom_bar(aes(country, n), stat = \"identity\")+\n  labs(y=\"number of guests\", title = \"most guests by country's\")+\n  coord_flip()\n\n\n\n\nhow much do guests pay for a room at each hotel?\n\n\ncity_hotel_data<-filter(hotel_bookings, hotel_bookings$hotel==\"City Hotel\")\nresort_hotel_data<-filter(hotel_bookings, hotel_bookings$hotel==\"Resort Hotel\")\n\n\n\nadr - average daily rate\n\n\n# city hotel\nsort(unique(city_hotel_data$reserved_room_type))\n\n\n[1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"P\"\n\n# resort hotel\nsort(unique(resort_hotel_data$reserved_room_type))\n\n\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"L\" \"P\"\n\ncity hotel average guests per room type\n\n\n(city_hotel_average_guests_per_room_type <- city_hotel_data %>% \n   group_by(reserved_room_type) %>% \n   summarise(guests_per_room_type = mean(adults+children)))\n\n\n# A tibble: 8 × 2\n  reserved_room_type guests_per_room_type\n  <chr>                             <dbl>\n1 A                                  1.82\n2 B                                  2.12\n3 C                                  1.64\n4 D                                  2.21\n5 E                                  2.34\n6 F                                  3.62\n7 G                                  3.29\n8 P                                  0   \n\ncity hotel average daily rate per room type\n\n\n(city_hotel_adr_per_room_type_data <- city_hotel_data %>% \n   group_by(reserved_room_type) %>% \n   summarise(adr_per_room_type = mean(adr)))\n\n\n# A tibble: 8 × 2\n  reserved_room_type adr_per_room_type\n  <chr>                          <dbl>\n1 A                               96.2\n2 B                               90.5\n3 C                               85.5\n4 D                              131. \n5 E                              157. \n6 F                              189. \n7 G                              202. \n8 P                                0  \n\nresort hotel average guests per room type\n\n\n(resort_average_guests_per_room_type <- resort_hotel_data %>% \n   group_by(reserved_room_type) %>% \n   summarise(guests_per_room_type = mean(adults+children)))\n\n\n# A tibble: 10 × 2\n   reserved_room_type guests_per_room_type\n   <chr>                             <dbl>\n 1 A                                  1.80\n 2 B                                  2   \n 3 C                                  3.34\n 4 D                                  2.00\n 5 E                                  1.99\n 6 F                                  2.05\n 7 G                                  3.37\n 8 H                                  3.69\n 9 L                                  2.17\n10 P                                  0   \n\n##resort hotel average daily rate per room type\n\n\n(resort_hotel_adr_per_room_type_data <- resort_hotel_data %>% \n   group_by(reserved_room_type) %>% \n   summarise(adr_per_room_type = mean(adr)))\n\n\n# A tibble: 10 × 2\n   reserved_room_type adr_per_room_type\n   <chr>                          <dbl>\n 1 A                               76.2\n 2 B                              105. \n 3 C                              161. \n 4 D                              104. \n 5 E                              114. \n 6 F                              133. \n 7 G                              168. \n 8 H                              188. \n 9 L                              125. \n10 P                                0  \n\nvisualizing Average daily rate of reserved room type at city hotel and resort hotel\n\n\nggplot(city_hotel_adr_per_room_type_data, aes(x=reserved_room_type, y= adr_per_room_type))+\n  geom_bar(stat = \"identity\",fill = \"steelblue\", width = .5)+\n  labs(x=\"reserved room type\", y=\" average daily rate per room\", title = \"Average daily rate of reserved room type at city hotel\")+\n  theme(plot.title = element_text(size = 14, hjust = 0.5, face = \"bold\"))\n\n\n\n\n\n\nggplot(resort_hotel_adr_per_room_type_data, aes(x=reserved_room_type, y= adr_per_room_type))+\n  geom_bar(stat = \"identity\",fill = \"steelblue\", width = .5)+\n  labs(x=\"reserved room type\", y=\" average daily rate per room\", title = \"Average daily rate of reserved room type at resort hotel\")+\n  theme(plot.title = element_text(size = 14, hjust = 0.5, face = \"bold\"))\n\n\n\n\nhow does the price per night varry in the year in each hotel?\ncity hotel\n\n\ncity_room_prices_monthly <-select(city_hotel_data, arrival_date_month, adr)\n(city_room_prices_monthly <- city_room_prices_monthly %>%\n    group_by(arrival_date_month) %>%\n    summarise(mean_room_prices = mean(adr)) %>% \n    ungroup() %>% \n  arrange(desc(mean_room_prices)))\n\n\n# A tibble: 12 × 2\n   arrival_date_month mean_room_prices\n   <chr>                         <dbl>\n 1 May                           122. \n 2 June                          119. \n 3 August                        115. \n 4 April                         111. \n 5 July                          111. \n 6 September                     110. \n 7 October                       100. \n 8 March                          92.6\n 9 December                       88.8\n10 November                       88.1\n11 February                       85.1\n12 January                        82.6\n\n\n\nplot <- ggplot(city_room_prices_monthly)+\n  geom_bar(aes(arrival_date_month, mean_room_prices),stat = \"identity\")+\n  labs(x=\"arrival_date_month\", y=\" mean_room_prices\", title = \"mean room prices over the year at city hotel\")+\n  theme(plot.title = element_text(size = 14, hjust = 0.5, face = \"bold\"))\n  \n\nplot +\n  scale_x_discrete(limits = c(\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \n          \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"))\n\n\n\n\nresort hotel\n\n\nresort_room_prices_monthly <-select(resort_hotel_data, arrival_date_month, adr)\n(resort_room_prices_monthly <- resort_room_prices_monthly %>%\n    group_by(arrival_date_month) %>%\n    summarise(mean_room_prices = mean(adr)) %>% \n    ungroup() %>% \n  arrange(desc(mean_room_prices)))\n\n\n# A tibble: 12 × 2\n   arrival_date_month mean_room_prices\n   <chr>                         <dbl>\n 1 August                        187. \n 2 July                          155. \n 3 June                          110. \n 4 September                      93.3\n 5 May                            78.8\n 6 April                          77.8\n 7 December                       69.0\n 8 October                        62.1\n 9 March                          57.5\n10 February                       55.2\n11 January                        49.5\n12 November                       48.3\n\n\n\nplot <- ggplot(resort_room_prices_monthly)+\n  geom_bar(aes(arrival_date_month, mean_room_prices),stat = \"identity\")+\n  labs(x=\"arrival_date_month\", y=\" mean_room_prices\", title = \"mean room prices over the year at resort hotel\")+\n  theme(plot.title = element_text(size = 14, hjust = 0.5, face = \"bold\"))\n  \n\nplot +\n  scale_x_discrete(limits = c(\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \n          \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"))\n\n\n\n\nwhich months are the busiest?\n\n\n\n\n\n\n",
    "preview": "posts/2021-08-18-sathvikhotelbookingsdatahw3/sathvik_hotel_bookings_data_hw3_files/figure-html5/unnamed-chunk-11-1.png",
    "last_modified": "2021-08-20T15:46:45-04:00",
    "input_file": "sathvik_hotel_bookings_data_hw3.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-08-18-sathvikirisdatahw2/",
    "title": "sathvik_iris_data_hw2",
    "description": "the Iris dataset",
    "author": [
      {
        "name": "sathvik_thogaru",
        "url": {}
      }
    ],
    "date": "2021-08-18",
    "categories": [],
    "contents": "\nloading the iris dataset from the datasets package and running summary statistics on the iris data\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n\nfinding the column nammes of the data\n\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\" \n[5] \"Species\"     \n\ndim()is used to find the dimensions of the data\n\n[1] 150   5\n\nskim() is an alternative to summary(), quickly providing a broad overview of a data frame. It handles data of all types, dispatching a different set of summary functions based on the types of columns in the data frame.\n\nTable 1: Data summary\nName\niris\nNumber of rows\n150\nNumber of columns\n5\n_______________________\n\nColumn type frequency:\n\nfactor\n1\nnumeric\n4\n________________________\n\nGroup variables\nNone\nVariable type: factor\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\nSpecies\n0\n1\nFALSE\n3\nset: 50, ver: 50, vir: 50\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nSepal.Length\n0\n1\n5.84\n0.83\n4.3\n5.1\n5.80\n6.4\n7.9\n▆▇▇▅▂\nSepal.Width\n0\n1\n3.06\n0.44\n2.0\n2.8\n3.00\n3.3\n4.4\n▁▆▇▂▁\nPetal.Length\n0\n1\n3.76\n1.77\n1.0\n1.6\n4.35\n5.1\n6.9\n▇▁▆▇▂\nPetal.Width\n0\n1\n1.20\n0.76\n0.1\n0.3\n1.30\n1.8\n2.5\n▇▁▇▅▃\n\nthere are 4 numeric variables and 1 factor variable which is the species. there are a total of 3 unique species in the iris\n\n[1] setosa     versicolor virginica \nLevels: setosa versicolor virginica\n\nthe three species are setosa, versicolor and virginica\nploting iris\n\n\n\n\n\n\n",
    "preview": "posts/2021-08-18-sathvikirisdatahw2/sathvik_iris_data_hw2_files/figure-html5/unnamed-chunk-6-1.png",
    "last_modified": "2021-08-20T15:46:47-04:00",
    "input_file": "sathvik_iris_data_hw2.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-08-18-sathvikthogaruhomework4/",
    "title": "sathvik_thogaru_homework4",
    "description": "hotel_bookings Dataset",
    "author": [
      {
        "name": "sathvik_thogaru",
        "url": {}
      }
    ],
    "date": "2021-08-18",
    "categories": [],
    "contents": "\nImporting data\nThis data set contains a single file which compares various booking information between hotels.\n\n\n\nimporting the data and reading the top 5 rows\n\n# A tibble: 6 × 32\n  hotel        is_canceled lead_time arrival_date_ye… arrival_date_mo…\n  <chr>              <dbl>     <dbl>            <dbl> <chr>           \n1 Resort Hotel           0       342             2015 July            \n2 Resort Hotel           0       737             2015 July            \n3 Resort Hotel           0         7             2015 July            \n4 Resort Hotel           0        13             2015 July            \n5 Resort Hotel           0        14             2015 July            \n6 Resort Hotel           0        14             2015 July            \n# … with 27 more variables: arrival_date_week_number <dbl>,\n#   arrival_date_day_of_month <dbl>, stays_in_weekend_nights <dbl>,\n#   stays_in_week_nights <dbl>, adults <dbl>, children <dbl>,\n#   babies <dbl>, meal <chr>, country <chr>, market_segment <chr>,\n#   distribution_channel <chr>, is_repeated_guest <dbl>,\n#   previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>, …\n\nskim() is used to for getting summary statistics about variables in dataframe,tibbles,datatablesand vectors. It is mostly used with grouped dataframes (source: https://cran.r-project.org/web/packages/skimr/vignettes/skimr.html)\n\nTable 1: Data summary\nName\nhotel_bookings\nNumber of rows\n119390\nNumber of columns\n32\n_______________________\n\nColumn type frequency:\n\ncharacter\n13\nDate\n1\nnumeric\n18\n________________________\n\nGroup variables\nNone\nVariable type: character\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\nhotel\n0\n1\n10\n12\n0\n2\n0\narrival_date_month\n0\n1\n3\n9\n0\n12\n0\nmeal\n0\n1\n2\n9\n0\n5\n0\ncountry\n0\n1\n2\n4\n0\n178\n0\nmarket_segment\n0\n1\n6\n13\n0\n8\n0\ndistribution_channel\n0\n1\n3\n9\n0\n5\n0\nreserved_room_type\n0\n1\n1\n1\n0\n10\n0\nassigned_room_type\n0\n1\n1\n1\n0\n12\n0\ndeposit_type\n0\n1\n10\n10\n0\n3\n0\nagent\n0\n1\n1\n4\n0\n334\n0\ncompany\n0\n1\n1\n4\n0\n353\n0\ncustomer_type\n0\n1\n5\n15\n0\n4\n0\nreservation_status\n0\n1\n7\n9\n0\n3\n0\nVariable type: Date\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\nreservation_status_date\n0\n1\n2014-10-17\n2017-09-14\n2016-08-07\n926\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nis_canceled\n0\n1\n0.37\n0.48\n0.00\n0.00\n0.00\n1\n1\n▇▁▁▁▅\nlead_time\n0\n1\n104.01\n106.86\n0.00\n18.00\n69.00\n160\n737\n▇▂▁▁▁\narrival_date_year\n0\n1\n2016.16\n0.71\n2015.00\n2016.00\n2016.00\n2017\n2017\n▃▁▇▁▆\narrival_date_week_number\n0\n1\n27.17\n13.61\n1.00\n16.00\n28.00\n38\n53\n▅▇▇▇▅\narrival_date_day_of_month\n0\n1\n15.80\n8.78\n1.00\n8.00\n16.00\n23\n31\n▇▇▇▇▆\nstays_in_weekend_nights\n0\n1\n0.93\n1.00\n0.00\n0.00\n1.00\n2\n19\n▇▁▁▁▁\nstays_in_week_nights\n0\n1\n2.50\n1.91\n0.00\n1.00\n2.00\n3\n50\n▇▁▁▁▁\nadults\n0\n1\n1.86\n0.58\n0.00\n2.00\n2.00\n2\n55\n▇▁▁▁▁\nchildren\n4\n1\n0.10\n0.40\n0.00\n0.00\n0.00\n0\n10\n▇▁▁▁▁\nbabies\n0\n1\n0.01\n0.10\n0.00\n0.00\n0.00\n0\n10\n▇▁▁▁▁\nis_repeated_guest\n0\n1\n0.03\n0.18\n0.00\n0.00\n0.00\n0\n1\n▇▁▁▁▁\nprevious_cancellations\n0\n1\n0.09\n0.84\n0.00\n0.00\n0.00\n0\n26\n▇▁▁▁▁\nprevious_bookings_not_canceled\n0\n1\n0.14\n1.50\n0.00\n0.00\n0.00\n0\n72\n▇▁▁▁▁\nbooking_changes\n0\n1\n0.22\n0.65\n0.00\n0.00\n0.00\n0\n21\n▇▁▁▁▁\ndays_in_waiting_list\n0\n1\n2.32\n17.59\n0.00\n0.00\n0.00\n0\n391\n▇▁▁▁▁\nadr\n0\n1\n101.83\n50.54\n-6.38\n69.29\n94.58\n126\n5400\n▇▁▁▁▁\nrequired_car_parking_spaces\n0\n1\n0.06\n0.25\n0.00\n0.00\n0.00\n0\n8\n▇▁▁▁▁\ntotal_of_special_requests\n0\n1\n0.57\n0.79\n0.00\n0.00\n0.00\n1\n5\n▇▁▁▁▁\n\nfrom the above summary statistics we can see there are a total of 119390 rows and 32 columns in the hotel_bookings dataset. 13 character variables, 18 numeric variables, and 1 date variable. there are a total of 4 missing values in the children variable. for the analysis now i will be using hotel, market segment, stays_in_weekend_nights and stays_in_week_nights.\nVaraible Description\nhotel variable: type of hotel booked\nmarket segment : Market segment designation. In categories, the term “TA” means “Travel Agents” and “TO” means “Tour Operators”\nstays_in_weekend_nights : guest stayed at the hotel in weekend nights\nstays_in_week_nights : guest stayed at the hotel in week nights\nI am using the select() from the dplyr package which comes with tidyverse package and the piping for selecting columns\n\n# A tibble: 119,390 × 4\n   hotel        stays_in_weekend_ni… stays_in_week_nig… market_segment\n   <chr>                       <dbl>              <dbl> <chr>         \n 1 Resort Hotel                    0                  0 Direct        \n 2 Resort Hotel                    0                  0 Direct        \n 3 Resort Hotel                    0                  1 Direct        \n 4 Resort Hotel                    0                  1 Corporate     \n 5 Resort Hotel                    0                  2 Online TA     \n 6 Resort Hotel                    0                  2 Online TA     \n 7 Resort Hotel                    0                  2 Direct        \n 8 Resort Hotel                    0                  2 Direct        \n 9 Resort Hotel                    0                  3 Online TA     \n10 Resort Hotel                    0                  3 Offline TA/TO \n# … with 119,380 more rows\n\n\n[1] \"Resort Hotel\" \"City Hotel\"  \n[1] \"Direct\"        \"Corporate\"     \"Online TA\"     \"Offline TA/TO\"\n[5] \"Complementary\" \"Groups\"        \"Undefined\"     \"Aviation\"     \n\n\n\n\nbookings in different market segments\ncity hotel\n\n# A tibble: 8 × 2\n  market_segment     n\n  <chr>          <int>\n1 Aviation         237\n2 Complementary    542\n3 Corporate       2986\n4 Direct          6093\n5 Groups         13975\n6 Offline TA/TO  16747\n7 Online TA      38748\n8 Undefined          2\n\n\nresort hotel\n\n# A tibble: 6 × 2\n  market_segment     n\n  <chr>          <int>\n1 Complementary    201\n2 Corporate       2309\n3 Direct          6513\n4 Groups          5836\n5 Offline TA/TO   7472\n6 Online TA      17729\n\n\n\n# A tibble: 14 × 3\n# Groups:   hotel, market_segment [14]\n   hotel        market_segment     n\n   <chr>        <chr>          <int>\n 1 City Hotel   Aviation         237\n 2 City Hotel   Complementary    542\n 3 City Hotel   Corporate       2986\n 4 City Hotel   Direct          6093\n 5 City Hotel   Groups         13975\n 6 City Hotel   Offline TA/TO  16747\n 7 City Hotel   Online TA      38748\n 8 City Hotel   Undefined          2\n 9 Resort Hotel Complementary    201\n10 Resort Hotel Corporate       2309\n11 Resort Hotel Direct          6513\n12 Resort Hotel Groups          5836\n13 Resort Hotel Offline TA/TO   7472\n14 Resort Hotel Online TA      17729\n\n\n\n\nhow many number of days do people stay in the hotel?\nResort hotel\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-08-18-sathvikthogaruhomework4/sathvik_thogaru_hw4_files/figure-html5/unnamed-chunk-7-1.png",
    "last_modified": "2021-08-20T15:46:57-04:00",
    "input_file": "sathvik_thogaru_hw4.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-08-16-railroad-employment-data/",
    "title": "Railroad Employment data",
    "description": "Reading in the railroad dataset",
    "author": [
      {
        "name": "Mohit-Arora",
        "url": {}
      }
    ],
    "date": "2021-08-17",
    "categories": [],
    "contents": "\n\n\nlibrary(readxl)\n  library(dplyr)\n  State_county <- read_excel(\"../../_data/StateCounty2012.xls\", skip=3)\n  \n\n\nThe data has been read in. Let’s see how it looks like -\n\n\nhead(State_county)\n\n\n# A tibble: 6 × 5\n  STATE     ...2  COUNTY               ...4  TOTAL\n  <chr>     <lgl> <chr>                <lgl> <dbl>\n1 AE        NA    APO                  NA        2\n2 AE Total1 NA    <NA>                 NA        2\n3 AK        NA    ANCHORAGE            NA        7\n4 AK        NA    FAIRBANKS NORTH STAR NA        2\n5 AK        NA    JUNEAU               NA        3\n6 AK        NA    MATANUSKA-SUSITNA    NA        2\n\ntail(State_county)\n\n\n# A tibble: 6 × 5\n  STATE                                       ...2  COUNTY ...4  TOTAL\n  <chr>                                       <lgl> <chr>  <lgl> <dbl>\n1 <NA>                                        NA    <NA>   NA       NA\n2 CANADA                                      NA    <NA>   NA      662\n3 <NA>                                        NA    <NA>   NA       NA\n4 1  Military designation.                    NA    <NA>   NA       NA\n5 <NA>                                        NA    <NA>   NA       NA\n6 NOTE:  Excludes 2,896 employees without an… NA    <NA>   NA       NA\n\nThis needs further cleaning to make it suitable for further analysis.\n\n\nState_county <- select(State_county, -c(2, 4))\nState_county <- State_county[complete.cases(State_county),]\nhead(State_county)\n\n\n# A tibble: 6 × 3\n  STATE COUNTY               TOTAL\n  <chr> <chr>                <dbl>\n1 AE    APO                      2\n2 AK    ANCHORAGE                7\n3 AK    FAIRBANKS NORTH STAR     2\n4 AK    JUNEAU                   3\n5 AK    MATANUSKA-SUSITNA        2\n6 AK    SITKA                    1\n\ntail(State_county)\n\n\n# A tibble: 6 × 3\n  STATE COUNTY     TOTAL\n  <chr> <chr>      <dbl>\n1 WY    SHERIDAN     252\n2 WY    SUBLETTE       3\n3 WY    SWEETWATER   196\n4 WY    UINTA         49\n5 WY    WASHAKIE      10\n6 WY    WESTON        37\n\nThis looks much better!\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:45:54-04:00",
    "input_file": "railroad-employment-data.knit.md"
  },
  {
    "path": "posts/2021-08-17-dn-australian-data/",
    "title": "DN Australian Data",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Dana Nestor",
        "url": {}
      }
    ],
    "date": "2021-08-17",
    "categories": [],
    "contents": "\nImporting data using a specific range to isolate desired variables, renaming variables to add meaningful values and allow for easier selecting, removing interstitial undesirable variables\n\n\nbase_marriage_data <- read_excel(\"../../_data/australian_marriage_law_postal_survey_2017_-_response_final.xls\", \n         sheet = \"Table 2\", \n         range = \"A8:P179\", \n         col_names = c(\"Town\", \"Yes\", \"d\", \"No\", rep(\"d\", 6), \"Not Clear\", \"d\", \n                       \"No Response\", rep(\"d\", 3)))%>%\n  select(!starts_with(\"d\"))\n\n\n\nThe next variable we need to isolate is County which, in this data set, has a parent-child relationship with Town. To accomplish this, we will create a new column for County values that correlate with their child towns and order the columns in descending complexity (in this case, county then town)\n\n\nbase_marriage_data <- base_marriage_data%>%\n  mutate(County = case_when(\n    str_ends(Town, \"Divisions\") ~ Town, \n    TRUE ~ NA_character_))%>%\n# Because I cannot get the .before or .after arguments to work with mutate(), I am using the relocate() function to move the County column before the Town column so we can maintain a descending order of complexity in governmental organizations\n  relocate(County, .before = Town)\n\n\n\nTo complete the isolation of County data, we need to populate our new column with the appropriate parent-county for their associated child-towns. We use a loop function to pull the County value down our column, stopping when a new county is reached and then restarting itself with the new county value.\n\n\ntidy_marriage_data <- base_marriage_data\nfor(i in seq_along(tidy_marriage_data$County)) {tidy_marriage_data$County[i] <- ifelse(is.na(tidy_marriage_data$County[i]), tidy_marriage_data$County[i-1], tidy_marriage_data$County[i])}\n\n\n\nThis next chunk removes undesirable rows so we can isolate our observations. Since we were able to import our data with a range that cut out unnecessary rows above and below our data frame, now we need to account for interstitial rows without data and rows with totals\n\n\ntidier_marriage_data <- tidy_marriage_data%>%drop_na(Town, Yes)%>%\n  filter(!str_detect(Town, \"(Total)\"))\n\n\n\nAs an extra step to tidy the data, we can remove “Divisions” in the County column as this variable is now describing the county itself, not the child-towns.\n\n\ntidiest_marriage_data <- mutate(tidier_marriage_data, County = str_remove(County, \" Divisions\"))%>%\n  mutate(Town = str_remove(Town, \"\\\\([cde]\\\\)\"))\n  view(tidiest_marriage_data)\n\n\n\nNOTE tidy objects, condense code (under 15 lines?)\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:45:58-04:00",
    "input_file": "dn-australian-data.knit.md"
  },
  {
    "path": "posts/2021-08-17-example-code-for-pivot-longer/",
    "title": "Example Code for Pivot Longer",
    "description": "I'm sharing some example code for pivot_longer using the eggs data. Enjoy!",
    "author": [
      {
        "name": "Meredith Rolfe",
        "url": {}
      }
    ],
    "date": "2021-08-17",
    "categories": [
      "example code",
      "data cleaning"
    ],
    "contents": "\nThis is example code for using the pivot functions in R. Several of the government data sources include tabular data that really need to be pivoted into a dataset in which a “case” is some combination of the grouping variables (the rows and columns in the table) alongside the appropriate statistical value(s) in the table (e.g., counts or average costs). Lets start with the easy to read in eggs_tidy.csv just so we can focus on the pivoting function.\n\n\neggs<-read_csv(\"../../_data/eggs_tidy.csv\", show_col_types = FALSE)\neggs\n\n\n# A tibble: 120 × 6\n   month      year large_half_dozen large_dozen extra_large_half_dozen\n   <chr>     <dbl>            <dbl>       <dbl>                  <dbl>\n 1 January    2004             126         230                    132 \n 2 February   2004             128.        226.                   134.\n 3 March      2004             131         225                    137 \n 4 April      2004             131         225                    137 \n 5 May        2004             131         225                    137 \n 6 June       2004             134.        231.                   137 \n 7 July       2004             134.        234.                   137 \n 8 August     2004             134.        234.                   137 \n 9 September  2004             130.        234.                   136.\n10 October    2004             128.        234.                   136.\n# … with 110 more rows, and 1 more variable: extra_large_dozen <dbl>\n\nLooking at the data, we can see that each case consists of a year-month combination (e.g., January 2004), while the values are the average price (in cents) of four different types of eggs (e.g., large_half_dozen, large_dozen, etc) But really, wouldn’t it possibly make more sense to consider the case as a year-month-type combination, with a single price value for each case?\nPivot Longer - One New Category Variable\nTo do this (and make our data easier to graph and analyze), we can pivot longer - changing our data from 120 rows with 6 variables (2 grouping and 4 values) to 480 rows of 4 variables (with 3 grouping variables and a single price value).\n\n\neggs%>%\n  pivot_longer(cols=large_half_dozen:extra_large_dozen, \n               names_to = \"eggType\",\n               values_to = \"avgPrice\"\n  )\n\n\n# A tibble: 480 × 4\n   month     year eggType                avgPrice\n   <chr>    <dbl> <chr>                     <dbl>\n 1 January   2004 large_half_dozen           126 \n 2 January   2004 large_dozen                230 \n 3 January   2004 extra_large_half_dozen     132 \n 4 January   2004 extra_large_dozen          230 \n 5 February  2004 large_half_dozen           128.\n 6 February  2004 large_dozen                226.\n 7 February  2004 extra_large_half_dozen     134.\n 8 February  2004 extra_large_dozen          230 \n 9 March     2004 large_half_dozen           131 \n10 March     2004 large_dozen                225 \n# … with 470 more rows\n\nWell, that was super easy. But wait, what if you are interested in egg size - you want to know how much more expensive extra-large eggs are compared to large eggs. Right now, that will be annoying, as you will have to keep sorting out the egg quantity - whether the price is for a half_dozen or a dozen eggs. Wouldn’t it be nice if we didn’t have a long egg type column with both size and quantity squashed into a single categorical variable? It would be so useful to have a new dataset with 4 grouping variables (year, month, size, and quantity) and the same value (price).\nPivot Longer - Two New Category Variables\nSo, once again we want to use pivot longer, but we will be adding two new category variables (for a total of 4) and this will cut the number of rows in half (to 240). But how in the world can we let R know what we want it to do?? Thankfully, someone named the egg types (column-names) pretty systematically, but how can use this to our advantage? Working with patterns in the names_sep option of the pivot functions makes it pretty easy (well, except our variable names have more than one underscore, so we have to sort of hack this part by also using mutate on the resulting category labels.)\n\n\neggs%>%\n  pivot_longer(cols=large_half_dozen:extra_large_dozen,\n               names_to = c(\"size\", \"quantity\"),\n               names_sep=\"arge_\",\n               values_to = \"price\"\n  ) %>%\n  mutate(size = case_when(\n    size == \"l\" ~ \"Large\",\n    size == \"extra_l\" ~ \"Extra Large\"\n  ))\n\n\n# A tibble: 480 × 5\n   month     year size        quantity   price\n   <chr>    <dbl> <chr>       <chr>      <dbl>\n 1 January   2004 Large       half_dozen  126 \n 2 January   2004 Large       dozen       230 \n 3 January   2004 Extra Large half_dozen  132 \n 4 January   2004 Extra Large dozen       230 \n 5 February  2004 Large       half_dozen  128.\n 6 February  2004 Large       dozen       226.\n 7 February  2004 Extra Large half_dozen  134.\n 8 February  2004 Extra Large dozen       230 \n 9 March     2004 Large       half_dozen  131 \n10 March     2004 Large       dozen       225 \n# … with 470 more rows\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:46:00-04:00",
    "input_file": "example-code-for-pivot-longer-railroad.knit.md"
  },
  {
    "path": "posts/2021-08-17-hw02/",
    "title": "HW02",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "TMoraitis",
        "url": {}
      }
    ],
    "date": "2021-08-17",
    "categories": [],
    "contents": "\n\n\n#Loading Library\nlibrary(tidyverse)\n\n\n\n##Data\n\n\npoultry <- read_csv(file=\"../../_data/poultry_tidy.csv\")\nhead(poultry)\n\n\n# A tibble: 6 × 4\n  Product  Year Month    Price_Dollar\n  <chr>   <dbl> <chr>           <dbl>\n1 Whole    2013 January          2.38\n2 Whole    2013 February         2.38\n3 Whole    2013 March            2.38\n4 Whole    2013 April            2.38\n5 Whole    2013 May              2.38\n6 Whole    2013 June             2.38\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:46:02-04:00",
    "input_file": "hw02.knit.md"
  },
  {
    "path": "posts/2021-08-17-hw03/",
    "title": "HW03",
    "description": "This is my submission of HW3",
    "author": [],
    "date": "2021-08-17",
    "categories": [],
    "contents": "\n\n\n#Loading Library\nlibrary(tidyverse)\n\n\n\n\n\n# Reading file\nhotelBookings <- read_csv(file=\"../../_data/hotel_bookings.csv\") \n\n#Using required functions\nhotelBookings %>%\n  select(1:4) %>%\n  filter(arrival_date_year==2015) %>%\n  arrange(4)\n\n\n# A tibble: 21,996 × 4\n   hotel        is_canceled lead_time arrival_date_year\n   <chr>              <dbl>     <dbl>             <dbl>\n 1 Resort Hotel           0       342              2015\n 2 Resort Hotel           0       737              2015\n 3 Resort Hotel           0         7              2015\n 4 Resort Hotel           0        13              2015\n 5 Resort Hotel           0        14              2015\n 6 Resort Hotel           0        14              2015\n 7 Resort Hotel           0         0              2015\n 8 Resort Hotel           0         9              2015\n 9 Resort Hotel           1        85              2015\n10 Resort Hotel           1        75              2015\n# … with 21,986 more rows\n\nhotelBookings %>%\n  group_by(hotel) %>%\n  summarise(mean = mean(adr), n = n())\n\n\n# A tibble: 2 × 3\n  hotel         mean     n\n  <chr>        <dbl> <int>\n1 City Hotel   105.  79330\n2 Resort Hotel  95.0 40060\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:46:05-04:00",
    "input_file": "hw03.knit.md"
  },
  {
    "path": "posts/2021-08-17-hw3nathaniel/",
    "title": "HW3Nathaniel",
    "description": "Reading in marriage data",
    "author": [],
    "date": "2021-08-17",
    "categories": [],
    "contents": "\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:46:09-04:00",
    "input_file": "hw3nathaniel.knit.md"
  },
  {
    "path": "posts/2021-08-17-noahhw3/",
    "title": "NoahHw3",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Noah Milstein",
        "url": {}
      }
    ],
    "date": "2021-08-17",
    "categories": [],
    "contents": "\nChicken Data In the code below I am loading all of the packages I will be using throughout this assignment\n\n\nlibrary(tidyverse) \nlibrary(dplyr) \nlibrary(knitr) \nlibrary(readxl) \nlibrary(ggplot2) \nlibrary(broom) \n\n\n\nThe code below is my file path for importing the data regarding chicken meat prices in excel form\n\n\npoultry <- read_excel(\"../../_data/poultry_tidy.xlsx\") \n\n\n\nThe Poultry The Poultry data is broken into 4 columns, Product which is the cut of chicken, Year and Month corresponding to each observation. Price_Dollar represents the price of each cut at a month and year.\n\n\npoultry \n\n\n# A tibble: 600 × 4\n   Product  Year Month     Price_Dollar\n   <chr>   <dbl> <chr>            <dbl>\n 1 Whole    2013 January           2.38\n 2 Whole    2013 February          2.38\n 3 Whole    2013 March             2.38\n 4 Whole    2013 April             2.38\n 5 Whole    2013 May               2.38\n 6 Whole    2013 June              2.38\n 7 Whole    2013 July              2.38\n 8 Whole    2013 August            2.38\n 9 Whole    2013 September         2.38\n10 Whole    2013 October           2.38\n# … with 590 more rows\n\nBelow is my initial data table manipulation which I did to get a specific product, in this case boneless breast with its price and the year in which that price was observed\n\n\npoultry %>% group_by(`Price_Dollar`)%>% \n  \n# first line groups the data by the price in the \n#Price_Dollar column so the data in the column is sorted into chunks of the same price. \n  \nselect(!(`Month`))%>% \n  \n# This select function selects all columns except for the one called \"Month\" \n  \nfilter(Product==\"B/S Breast\") %>% \n  \n# The line above selects only the Product in the \n#\"Product\" column called \"B/S Breast, or boneless chicken breast\" \n  \narrange(desc(`Price_Dollar`)) %>% \n\n# The above line sorts or arranges the column of \n# Price in dollars or \"Price_Dollar\" in descending order \n#starting above 7 dollars and going down closer to 6 dollars \nrename(Chicken_Bonless_Breast_Price=Price_Dollar)\n\n\n# A tibble: 120 × 3\n# Groups:   Chicken_Bonless_Breast_Price [8]\n   Product     Year Chicken_Bonless_Breast_Price\n   <chr>      <dbl>                        <dbl>\n 1 B/S Breast  2013                         7.04\n 2 B/S Breast  2013                         7.04\n 3 B/S Breast  2013                         7.04\n 4 B/S Breast  2013                         7.04\n 5 B/S Breast  2013                         7.04\n 6 B/S Breast  2013                         7.04\n 7 B/S Breast  2013                         7.04\n 8 B/S Breast  2013                         7.04\n 9 B/S Breast  2013                         7.04\n10 B/S Breast  2013                         7.04\n# … with 110 more rows\n\n# This above line renames the column \n#\"Price_Dollar\" into column \"Chicken_Boneless_Breast_Price\" \n# The line above takes the poultry data frame, it then finds the mean price in dollars and removes all N/A observations \n\n\n\n\n\nsummarise(poultry, mean(`Price_Dollar`, na.rm = TRUE)) \n\n\n# A tibble: 1 × 1\n  `mean(Price_Dollar, na.rm = TRUE)`\n                               <dbl>\n1                               3.39\n\nThe first line groups the data by the price in the Price_Dollar column so the data in the column is sorted into chunks of the same price.\nThe second line selects all columns except for the one called “Month”\nThe third line selects only the Product in the “Product” column called “B/S Breast, or boneless chicken breast”\nThe fourth line sorts or arranges the column of Price in dollars or “Price_Dollar” in descending order starting above 7 dollars and going down closer to 6 dollars This fifth line renames the column “Price_Dollar” into column “Chicken_Boneless_Breast_Price”\nThe final line of codes above takes the poultry data frame, it then finds the mean price in dollars and removes all N/A observations\n\n\npoultry %>% group_by(Year, Price_Dollar, Product) %>% ggplot() + geom_smooth(mapping=aes(y=Price_Dollar, x=Year, color=Product), na.rm=TRUE) \n\n\n\n\nPoultry Plot Post and Conclusion\nBy Noah Milstein\nChicken Data Conclusion\nThe graph above suggests that the price of most chicken cuts remain relatively similar over time, however B/S Breast or boneless chicken breast appears to have increased in price over recent years. Thighs have also remained relatively similar\n\n\n\n",
    "preview": "posts/2021-08-17-noahhw3/noahhw3_files/figure-html5/unnamed-chunk-6-1.png",
    "last_modified": "2021-08-20T15:46:14-04:00",
    "input_file": "noahhw3.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-08-16-hanae-homework-3/",
    "title": "Hanae- Homework 3",
    "description": "This is my submission of Homework 3.",
    "author": [
      {
        "name": "Hanae Bouazza",
        "url": {}
      }
    ],
    "date": "2021-08-16",
    "categories": [],
    "contents": "\n##Loading Library\n\n\nlibrary(tidyverse)\n\n\n\n##Data\n\n\nbookings<-read_csv(file=\"../../_data/hotel_bookings.csv\")\n\n\n\n##Using summarise() and group_by()\n\n\ngroup_by(bookings, hotel)%>%\nsummarise(meanAdr=mean(adr), n=n())\n\n\n# A tibble: 2 × 3\n  hotel        meanAdr     n\n  <chr>          <dbl> <int>\n1 City Hotel     105.  79330\n2 Resort Hotel    95.0 40060\n\n##Using arrange(), select(), and filter()\n\n\nstatusByCountry<-arrange(bookings, reservation_status)%>%\nselect(\"hotel\", \"country\", \"reservation_status\")\nfilter(statusByCountry, country==\"USA\")\n\n\n# A tibble: 2,097 × 3\n   hotel        country reservation_status\n   <chr>        <chr>   <chr>             \n 1 Resort Hotel USA     Canceled          \n 2 Resort Hotel USA     Canceled          \n 3 Resort Hotel USA     Canceled          \n 4 Resort Hotel USA     Canceled          \n 5 Resort Hotel USA     Canceled          \n 6 Resort Hotel USA     Canceled          \n 7 Resort Hotel USA     Canceled          \n 8 Resort Hotel USA     Canceled          \n 9 Resort Hotel USA     Canceled          \n10 Resort Hotel USA     Canceled          \n# … with 2,087 more rows\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:45:52-04:00",
    "input_file": "hanae-homework-3.knit.md"
  },
  {
    "path": "posts/2021-08-16-saulo-homework-two/",
    "title": "Saulo's Homeworks",
    "description": "Feeble attempts at data science.",
    "author": [
      {
        "name": "Saulo DePaula",
        "url": {}
      }
    ],
    "date": "2021-08-16",
    "categories": [
      "saulo",
      "homeworks",
      "read data"
    ],
    "contents": "\nHomework Two\n\n\nmarriage <- read.csv(\"../../_data/australian_marriage_tidy.csv\")\nhead(marriage)\n\n\n        territory resp   count percent\n1 New South Wales  yes 2374362    57.8\n2 New South Wales   no 1736838    42.2\n3        Victoria  yes 2145629    64.9\n4        Victoria   no 1161098    35.1\n5      Queensland  yes 1487060    60.7\n6      Queensland   no  961015    39.3\n\nHomework Three\nSelect\n\n\nlibrary(tidyverse)\nselect(marriage, \"territory\")\n\n\n                         territory\n1                  New South Wales\n2                  New South Wales\n3                         Victoria\n4                         Victoria\n5                       Queensland\n6                       Queensland\n7                  South Australia\n8                  South Australia\n9                Western Australia\n10               Western Australia\n11                        Tasmania\n12                        Tasmania\n13           Northern Territory(b)\n14           Northern Territory(b)\n15 Australian Capital Territory(c)\n16 Australian Capital Territory(c)\n\nFilter\n\n\nlibrary(tidyverse)\nfilter(marriage, `territory` == \"Victoria\")\n\n\n  territory resp   count percent\n1  Victoria  yes 2145629    64.9\n2  Victoria   no 1161098    35.1\n\nArrange\n\n\nlibrary(tidyverse)\nfilter(marriage, count > 500000) %>%\n  arrange(count)\n\n\n          territory resp   count percent\n1   South Australia  yes  592528    62.5\n2 Western Australia  yes  801575    63.7\n3        Queensland   no  961015    39.3\n4          Victoria   no 1161098    35.1\n5        Queensland  yes 1487060    60.7\n6   New South Wales   no 1736838    42.2\n7          Victoria  yes 2145629    64.9\n8   New South Wales  yes 2374362    57.8\n\nSummarize\n\n\nlibrary(tidyverse)\nsummarize(marriage, mean(`count`))\n\n\n  mean(count)\n1    793202.1\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:45:56-04:00",
    "input_file": "saulo-homework-two.knit.md"
  },
  {
    "path": "posts/2021-08-15-zoe-hotel-bookings-dataset/",
    "title": "Zoe Hotel Bookings Dataset",
    "description": "An introdution to the hotel dataset",
    "author": [
      {
        "name": "Zoe Bean",
        "url": {}
      }
    ],
    "date": "2021-08-15",
    "categories": [],
    "contents": "\nHomework 2\nI will be processing a dataset about hotel bookings from 2015 to 2017. First, I import the dataset, which requires the tidyverse package to be loaded.\n\n\nlibrary(tidyverse)\nhotel_data=read_csv(\"../../_data/hotel_bookings.csv\")\n\n\n\nNext, I use head() to give an example of what the dataset looks like.\n\n\nhead(hotel_data)\n\n\n# A tibble: 6 × 32\n  hotel        is_canceled lead_time arrival_date_ye… arrival_date_mo…\n  <chr>              <dbl>     <dbl>            <dbl> <chr>           \n1 Resort Hotel           0       342             2015 July            \n2 Resort Hotel           0       737             2015 July            \n3 Resort Hotel           0         7             2015 July            \n4 Resort Hotel           0        13             2015 July            \n5 Resort Hotel           0        14             2015 July            \n6 Resort Hotel           0        14             2015 July            \n# … with 27 more variables: arrival_date_week_number <dbl>,\n#   arrival_date_day_of_month <dbl>, stays_in_weekend_nights <dbl>,\n#   stays_in_week_nights <dbl>, adults <dbl>, children <dbl>,\n#   babies <dbl>, meal <chr>, country <chr>, market_segment <chr>,\n#   distribution_channel <chr>, is_repeated_guest <dbl>,\n#   previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>, …\n\nTo find out how many rows are in the dataset, I use dim(). I also use colnames() to figure out what the data drawn from each observation are.\n\n\ndim(hotel_data)\n\n\n[1] 119390     32\n\ncolnames(hotel_data)\n\n\n [1] \"hotel\"                          \"is_canceled\"                   \n [3] \"lead_time\"                      \"arrival_date_year\"             \n [5] \"arrival_date_month\"             \"arrival_date_week_number\"      \n [7] \"arrival_date_day_of_month\"      \"stays_in_weekend_nights\"       \n [9] \"stays_in_week_nights\"           \"adults\"                        \n[11] \"children\"                       \"babies\"                        \n[13] \"meal\"                           \"country\"                       \n[15] \"market_segment\"                 \"distribution_channel\"          \n[17] \"is_repeated_guest\"              \"previous_cancellations\"        \n[19] \"previous_bookings_not_canceled\" \"reserved_room_type\"            \n[21] \"assigned_room_type\"             \"booking_changes\"               \n[23] \"deposit_type\"                   \"agent\"                         \n[25] \"company\"                        \"days_in_waiting_list\"          \n[27] \"customer_type\"                  \"adr\"                           \n[29] \"required_car_parking_spaces\"    \"total_of_special_requests\"     \n[31] \"reservation_status\"             \"reservation_status_date\"       \n\nThe result from dim() means that there are 119390 rows and 32 columns. This is important since the number of rows tells us how many hotel bookings there are in this dataset, and the columns tell us how many pieces of data are available per booking.\nHomework 3\nThe colnames function is helpful for this next step, where I select columns. Here, I select the year of arrival and the month.\n\n\nselect(hotel_data, arrival_date_year, arrival_date_month )\n\n\n# A tibble: 119,390 × 2\n   arrival_date_year arrival_date_month\n               <dbl> <chr>             \n 1              2015 July              \n 2              2015 July              \n 3              2015 July              \n 4              2015 July              \n 5              2015 July              \n 6              2015 July              \n 7              2015 July              \n 8              2015 July              \n 9              2015 July              \n10              2015 July              \n# … with 119,380 more rows\n\nI can do more with select, such as selecting all columns that start with ‘arrival_date’ to get more clear information about when each the booking is.\n\n\nselect(hotel_data, starts_with(\"arrival_date\"))\n\n\n# A tibble: 119,390 × 4\n   arrival_date_ye… arrival_date_mo… arrival_date_we… arrival_date_da…\n              <dbl> <chr>                       <dbl>            <dbl>\n 1             2015 July                           27                1\n 2             2015 July                           27                1\n 3             2015 July                           27                1\n 4             2015 July                           27                1\n 5             2015 July                           27                1\n 6             2015 July                           27                1\n 7             2015 July                           27                1\n 8             2015 July                           27                1\n 9             2015 July                           27                1\n10             2015 July                           27                1\n# … with 119,380 more rows\n\nIf I want to look at all the bookings where there are no children, I use filter() as follows:\n\n\nfilter(hotel_data, children== 0)\n\n\n# A tibble: 110,796 × 32\n   hotel        is_canceled lead_time arrival_date_ye… arrival_date_mo…\n   <chr>              <dbl>     <dbl>            <dbl> <chr>           \n 1 Resort Hotel           0       342             2015 July            \n 2 Resort Hotel           0       737             2015 July            \n 3 Resort Hotel           0         7             2015 July            \n 4 Resort Hotel           0        13             2015 July            \n 5 Resort Hotel           0        14             2015 July            \n 6 Resort Hotel           0        14             2015 July            \n 7 Resort Hotel           0         0             2015 July            \n 8 Resort Hotel           0         9             2015 July            \n 9 Resort Hotel           1        85             2015 July            \n10 Resort Hotel           1        75             2015 July            \n# … with 110,786 more rows, and 27 more variables:\n#   arrival_date_week_number <dbl>, arrival_date_day_of_month <dbl>,\n#   stays_in_weekend_nights <dbl>, stays_in_week_nights <dbl>,\n#   adults <dbl>, children <dbl>, babies <dbl>, meal <chr>,\n#   country <chr>, market_segment <chr>, distribution_channel <chr>,\n#   is_repeated_guest <dbl>, previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>, …\n\nIf I want to arrange the hotel data by putting a column in order, I use arrange(). In this example, I order the data by the arrival month, which is sorted alphabetically.\n\n\narrange(hotel_data, arrival_date_month)\n\n\n# A tibble: 119,390 × 32\n   hotel        is_canceled lead_time arrival_date_ye… arrival_date_mo…\n   <chr>              <dbl>     <dbl>            <dbl> <chr>           \n 1 Resort Hotel           1        31             2016 April           \n 2 Resort Hotel           0         0             2016 April           \n 3 Resort Hotel           0       144             2016 April           \n 4 Resort Hotel           0       144             2016 April           \n 5 Resort Hotel           0       144             2016 April           \n 6 Resort Hotel           0       163             2016 April           \n 7 Resort Hotel           1        38             2016 April           \n 8 Resort Hotel           0       175             2016 April           \n 9 Resort Hotel           1        39             2016 April           \n10 Resort Hotel           1        32             2016 April           \n# … with 119,380 more rows, and 27 more variables:\n#   arrival_date_week_number <dbl>, arrival_date_day_of_month <dbl>,\n#   stays_in_weekend_nights <dbl>, stays_in_week_nights <dbl>,\n#   adults <dbl>, children <dbl>, babies <dbl>, meal <chr>,\n#   country <chr>, market_segment <chr>, distribution_channel <chr>,\n#   is_repeated_guest <dbl>, previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>, …\n\nIf I actually wanted to have the months in order, I would have to make a numerical variable in the dataset using mutate() and case_when() and then arrange by that variable.\n\n\nhotel_data<- hotel_data %>%\n  mutate(arrival_date_month_num = case_when(\n         arrival_date_month == \"January\" ~ 1,\n         arrival_date_month == \"February\" ~ 2,\n         arrival_date_month == \"March\" ~ 3,\n         arrival_date_month == \"April\" ~ 4,\n         arrival_date_month == \"May\" ~ 5,\n         arrival_date_month == \"June\" ~ 6,\n         arrival_date_month == \"July\" ~ 7,\n         arrival_date_month == \"August\" ~ 8,\n         arrival_date_month == \"September\" ~ 9,\n         arrival_date_month == \"October\" ~ 10,\n         arrival_date_month == \"November\" ~ 11,\n         arrival_date_month == \"December\" ~ 12\n         ))\n\narrange(hotel_data, arrival_date_month_num)\n\n\n# A tibble: 119,390 × 33\n   hotel        is_canceled lead_time arrival_date_ye… arrival_date_mo…\n   <chr>              <dbl>     <dbl>            <dbl> <chr>           \n 1 Resort Hotel           0       109             2016 January         \n 2 Resort Hotel           0       109             2016 January         \n 3 Resort Hotel           1         2             2016 January         \n 4 Resort Hotel           0        88             2016 January         \n 5 Resort Hotel           1        20             2016 January         \n 6 Resort Hotel           1        76             2016 January         \n 7 Resort Hotel           0        88             2016 January         \n 8 Resort Hotel           1       113             2016 January         \n 9 Resort Hotel           1       113             2016 January         \n10 Resort Hotel           1       113             2016 January         \n# … with 119,380 more rows, and 28 more variables:\n#   arrival_date_week_number <dbl>, arrival_date_day_of_month <dbl>,\n#   stays_in_weekend_nights <dbl>, stays_in_week_nights <dbl>,\n#   adults <dbl>, children <dbl>, babies <dbl>, meal <chr>,\n#   country <chr>, market_segment <chr>, distribution_channel <chr>,\n#   is_repeated_guest <dbl>, previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>, …\n\nIf I wanted to know the average amount of adults per booking, I would use summarise() like so:\n\n\nsummarise(hotel_data, mean=mean(adults))\n\n\n# A tibble: 1 × 1\n   mean\n  <dbl>\n1  1.86\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:45:38-04:00",
    "input_file": "zoe-hotel-bookings-dataset.knit.md"
  },
  {
    "path": "posts/2021-08-13-ishas-blog-post/",
    "title": "Isha's Blog Post",
    "description": "Running Blog Post for Course Homeworks",
    "author": [
      {
        "name": "Isha Akshita Mahajan",
        "url": {}
      }
    ],
    "date": "2021-08-13",
    "categories": [],
    "contents": "\n##Introduction\nHello Everybody! My name is Isha and I am starting the DACSS program this summer. I am from India and completed my bachelors in journalism and political science from UMass. I am excited to meet everyone this fall and delve into the world of data and social science.\n##Homework 2\n\n# A tibble: 6 × 4\n  territory       resp    count percent\n  <chr>           <chr>   <dbl>   <dbl>\n1 New South Wales yes   2374362    57.8\n2 New South Wales no    1736838    42.2\n3 Victoria        yes   2145629    64.9\n4 Victoria        no    1161098    35.1\n5 Queensland      yes   1487060    60.7\n6 Queensland      no     961015    39.3\n\n#About the Data This data sample is drawn from the Australian Marriage Law Postal Survey in 2017. Eligible participants were those who enrolled in the Commonwealth Electoral Roll by August 24 , 2017 and were 18 years of Age. They had not served prison sentences of three years and longer and participated in the survey voluntarily. The responses were recorded to the question\nShould the law be changed to allow same-sex couples to marry?\n##Homework 3\n\nHow can you arrange your dataset by territory?\n\n\n\n\n\nWhich Territory had the highest population count who voted yes to the law allowing same-sex couples to marry.\n\n\n\n\n\nRename the resp column to response.\n\n\n\n\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:45:28-04:00",
    "input_file": "ishas-blog-post.knit.md"
  },
  {
    "path": "posts/2021-08-19-nathanielreadindata/",
    "title": "Australian Marriage",
    "description": "Statistics About Australian Marriage",
    "author": [
      {
        "name": "Nathaniel Ross",
        "url": {}
      }
    ],
    "date": "2021-08-13",
    "categories": [],
    "contents": "\n\n# A tibble: 16 × 4\n   territory                       resp    count percent\n   <chr>                           <chr>   <dbl>   <dbl>\n 1 New South Wales                 yes   2374362    57.8\n 2 New South Wales                 no    1736838    42.2\n 3 Victoria                        yes   2145629    64.9\n 4 Victoria                        no    1161098    35.1\n 5 Queensland                      yes   1487060    60.7\n 6 Queensland                      no     961015    39.3\n 7 South Australia                 yes    592528    62.5\n 8 South Australia                 no     356247    37.5\n 9 Western Australia               yes    801575    63.7\n10 Western Australia               no     455924    36.3\n11 Tasmania                        yes    191948    63.6\n12 Tasmania                        no     109655    36.4\n13 Northern Territory(b)           yes     48686    60.6\n14 Northern Territory(b)           no      31690    39.4\n15 Australian Capital Territory(c) yes    175459    74  \n16 Australian Capital Territory(c) no      61520    26  \n\nRead in data on Australian Marriage\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:46:59-04:00",
    "input_file": "nathanielreadindata.knit.md"
  },
  {
    "path": "posts/2021-08-12-alligator-food/",
    "title": "Alligator Food",
    "description": "The diet of Alligators throughout several different lakes. Data has the lake, sex of alligator, size of food, and species of animal used for food.",
    "author": [],
    "date": "2021-08-12",
    "categories": [],
    "contents": "\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:45:19-04:00",
    "input_file": "alligator-food.knit.md"
  },
  {
    "path": "posts/2021-08-12-leahs-first-post-attempt-4/",
    "title": "Leah's first post: Attempt 4",
    "description": "My first blog post.",
    "author": [
      {
        "name": "Leah Dion",
        "url": {}
      }
    ],
    "date": "2021-08-12",
    "categories": [
      ".ruminating .random"
    ],
    "contents": "\nEducation/Work Background: I worked in retail management for many years and am currently entering my final semester to finish my undergraduate degree in Math/Stats.\nProgram: DACSS\nR experience: I used R for several classes and did several projects in the past few years.\nResearch interests: Public Policy, machine learning, criminal punishment system, and social movements\nHometown: South Hadley, MA\nHobbies: Music, basketball, spending time with my cat Jordan.\nFun fact: I have bowled a perfect game (300).\nBelow is a scatter plot of 250 randomly generated data points.\n\n\nknitr::opts_chunk$set(echo = TRUE)\n#set seed to reproduce results\nset.seed(327)\n#randomly generate 250 int from 1-100\nX <- sample.int(100, 250, replace=TRUE) \n#randomly generate 250 int from 1-100\nY <- sample.int(100, 250, replace=TRUE)\n#scatter plot of X, Y\nplot(X, Y, xlab=\"X Samples\", ylab=\"Y Samples\",\n     pch = 16, col = \"red\")\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-08-12-leahs-first-post-attempt-4/leahs-first-post-attempt-4_files/figure-html5/setup-1.png",
    "last_modified": "2021-08-20T15:45:23-04:00",
    "input_file": "leahs-first-post-attempt-4.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-08-12-wrangling-the-australian-marriage-law-dataset/",
    "title": "Wrangling the Australian marriage law dataset",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Karl Tacheron",
        "url": {}
      }
    ],
    "date": "2021-08-12",
    "categories": [],
    "contents": "\nThe Australian Bureau of Statistics 2017 Marriage Law Postal survey contains data about a nationwide vote that took place by mail. The data has a few things making reading into a tibble difficult:\nGrouped information instead of individual observations where variables appear elsewhere\nMany extraneous & repeated calculated variables\nMulti-index data formatted visually into blocks\nMulti-index column names with confusing and unhelpful names\nTo make this data usable we must transform its structure in both its column layout and its rows.\nWe read in the Excel file’s third sheet, cut it down to only the needed variables and rows, rename the columns, and remove NA values. We also remove rows that contain section totals.\n\n\nlibrary(tidyverse)\nlibrary(readxl)\n\nvotes <- read_excel(\"../../_data/australian_marriage_law_postal_survey_2017_-_response_final.xls\",\n           sheet=\"Table 2\",\n           skip=7,\n           col_names = c(\"Town\", \"Yes\", \"d\", \"No\", rep(\"d\", 6), \"Illegible\", \"d\", \"No Response\", rep(\"d\", 3)))%>%\n  select(!starts_with(\"d\"))%>%\n  drop_na(Town)%>%\n  filter(!str_detect(Town, \"(Total)\"))%>%\n  filter(!str_starts(Town, \"\\\\(\"))\n\n\n\nThe last step is more complicated. Each observation needs a variable for is administrative “division”, but this is displayed at the top of each block. These junk rows listing the parent division names must be turned into a variable for each row.\nWe get the number of each row that contains \" Divisions\".\n\n\nvotes<- votes%>%\n  mutate(Divisions = case_when(\n    str_ends(Town, \"Divisions\") ~ Town,\n    TRUE ~ NA_character_\n  ))\n\nfor(i in 1:length(votes$Divisions)){\n  votes$Divisions[i]<-ifelse(is.na(votes$Divisions[i]),votes$Divisions[i-1], votes$Divisions[i])\n}\n\nvotes<- filter(votes,!str_detect(Town, \"Divisions|Australia\"))\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:45:25-04:00",
    "input_file": "wrangling-the-australian-marriage-law-dataset.knit.md"
  },
  {
    "path": "posts/2021-08-11-2012-us-railroad-employment/",
    "title": "2012 US Railroad Employment",
    "description": "This is Shih-Yen's post on importing and tidying data",
    "author": [],
    "date": "2021-08-11",
    "categories": [],
    "contents": "\nHello, in this post, I will introduce the 2012 US Railroad Employment data, discuss some of the issues with the data, and provide the R code I used to import and tidy the data.\nFirst, let’s download the data. Since the data is in a .xls file, I used the readxl library that comes with the tidyverse package to import the data.\nlibrary(readxl)\nrailroad_data <- read_excel(\"StateCounty2012.xls\")\nview(railroad_data)\nWhen viewing the data, you might first see that the column names for the variables are incorrect and the correct column names are actually in the third row. This error occurs because there are 3 lines of metadata at the top of the file, and read_excel uses the first line as the column names. To fix this problem, we can use skip = 3 in read_excel to skip the first 3 lines.\nrailroad_data <- read_excel(\"StateCounty2012.xls\", skip = 3)\nNext, you might also see that there are two columns, column 2 and 4, that have nothing but NA as values. Here’s an easy way to get rid of those columns:\nrailroad_data <- railroad_data[,-c(2, 4)]\nFinally, it is likely that we are only interested in U.S. county-level data, but our data file also contains rows for state totals, a row for Canada, and a row for the grand total employment in U.S railroads. In addition, there are notes and footnotes that are not useful for the purpose of data analysis.\nTo get of these rows, I use the fact that all of these rows contain entries that have NA as a value, and the rows we want to keep do not. Hence, to clean our data of these rows, we simply get rid of any rows that contain NA as a value. We can achieve that with the following line of code that subsets the railroad_data by omitting all the rows containing NA:\nrailroad_data_clean <- na.omit(railroad_data)\nNow, we have a county-level data set with clearly defined column/variable names.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:44:55-04:00",
    "input_file": "2012-us-railroad-employment.knit.md"
  },
  {
    "path": "posts/2021-08-11-blog-1/",
    "title": "Larri Miller: Intro to [ ] Dataset",
    "description": "Blog Post 1",
    "author": [
      {
        "name": "Larri Miller",
        "url": {}
      }
    ],
    "date": "2021-08-11",
    "categories": [
      "Dataset type"
    ],
    "contents": "\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:44:57-04:00",
    "input_file": "blog-1.knit.md"
  },
  {
    "path": "posts/2021-08-11-first-post/",
    "title": "[First Post]",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Abhijit",
        "url": {}
      }
    ],
    "date": "2021-08-11",
    "categories": [],
    "contents": "\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:45:04-04:00",
    "input_file": "first-post.knit.md"
  },
  {
    "path": "posts/2021-08-11-hw1/",
    "title": "HW1",
    "description": "A short description of the post.",
    "author": [],
    "date": "2021-08-11",
    "categories": [
      "homework 1",
      "Antonis Gounalakis"
    ],
    "contents": "\n\n\nknitr::opts_chunk$set(echo = FALSE)\n\nvac_tn <- c(52.01,39.84,33.42,5.8,7.29,4.73,4.29,0.55)\npop <- c(83.78,60.46,46.75,10.42,10.2,8.65,5.79,0.89)\nvac_sh <- vac_tn/pop\nperc_vac_sh <- vac_sh*100\nperc_vac_sh > 70\n\n\n[1] FALSE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE\n\nAssuming that each vaccine dose provides full immunity and therefore is administered to different individuals, I examined the vaccination rates of 8 countries (Germany, Italy, Spain, Greece, Portugal, Switzerland, Denmark, Cypurs). I found that only in 3 cases (Spain, Portugal,Denmark) the herd immunity threshold of 70% has been reached!\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:45:06-04:00",
    "input_file": "hw1.knit.md"
  },
  {
    "path": "posts/2021-08-11-iris/",
    "title": "Arbitrary",
    "description": "My life in DACSS and with MAX :)",
    "author": [
      {
        "name": "Abhinav Kumar",
        "url": {}
      }
    ],
    "date": "2021-08-11",
    "categories": [],
    "contents": "\n\n\n# Analysis of Iris\n\nlibrary(datasets)\n\nsummary(iris)\n\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n\nplot(iris)\n\n\n\n\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": "posts/2021-08-11-iris/Abhinav_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-08-20T15:45:07-04:00",
    "input_file": "Abhinav.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-08-11-larri-miller-exploring-australian-marriage/",
    "title": "Larri Miller - Exploring Australian Marriage",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Larri Miller",
        "url": {}
      }
    ],
    "date": "2021-08-11",
    "categories": [],
    "contents": "\nHere I am reading in my CSV file.\n\n        territory resp   count percent\n1 New South Wales  yes 2374362    57.8\n2 New South Wales   no 1736838    42.2\n3        Victoria  yes 2145629    64.9\n4        Victoria   no 1161098    35.1\n5      Queensland  yes 1487060    60.7\n6      Queensland   no  961015    39.3\n\nThis dataset explores Australian marriage. It has 16 observations of 4 variables.\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:45:10-04:00",
    "input_file": "larri-miller-exploring-australian-marriage.knit.md"
  },
  {
    "path": "posts/2021-08-11-loading-data/",
    "title": "Loading a data set",
    "description": "Homework assignment to load data in to a R Markdown file.",
    "author": [
      {
        "name": "Karl Tacheron",
        "url": {}
      }
    ],
    "date": "2021-08-11",
    "categories": [],
    "contents": "\nLoad the tidyverse library:\n\n\nlibrary(tidyverse)\n\n\n\nImport a sample data set from the working directory and assign it to variable poultry:\n\n\npoultry<-read_csv('data/poultry_tidy.csv') \n\n\n\nFixed direction of the assignment - Meredith\nShow the first few values:\n\n\nhead(poultry)\n\n\n# A tibble: 6 × 4\n  Product  Year Month    Price_Dollar\n  <chr>   <dbl> <chr>           <dbl>\n1 Whole    2013 January          2.38\n2 Whole    2013 February         2.38\n3 Whole    2013 March            2.38\n4 Whole    2013 April            2.38\n5 Whole    2013 May              2.38\n6 Whole    2013 June             2.38\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:45:11-04:00",
    "input_file": "loading-data.knit.md"
  },
  {
    "path": "posts/2021-08-11-noahdata/",
    "title": "Noah_Chicken_Data",
    "description": "Included is a brief analysis of chicken data with a plot between year and the average price of each cut of chicken.",
    "author": [
      {
        "name": "Noah Milstein",
        "url": "http://umass.edu/sbs/dacss"
      }
    ],
    "date": "2021-08-11",
    "categories": [],
    "contents": "\n\n\n\n\n\npoultry <- read_csv(\"../../_data/eggs_tidy.csv\")\n\n\n\n\n\npoultry \n\n\n# A tibble: 120 × 6\n   month      year large_half_dozen large_dozen extra_large_half_dozen\n   <chr>     <dbl>            <dbl>       <dbl>                  <dbl>\n 1 January    2004             126         230                    132 \n 2 February   2004             128.        226.                   134.\n 3 March      2004             131         225                    137 \n 4 April      2004             131         225                    137 \n 5 May        2004             131         225                    137 \n 6 June       2004             134.        231.                   137 \n 7 July       2004             134.        234.                   137 \n 8 August     2004             134.        234.                   137 \n 9 September  2004             130.        234.                   136.\n10 October    2004             128.        234.                   136.\n# … with 110 more rows, and 1 more variable: extra_large_dozen <dbl>\n\nNote: This code isn’t running because the variables you are using aren’t in the original csv that I found - but this might be because you are using the poultry file not the eggs file. Sorry I couldn’t get it to work - Meredith\n\n\n#poultry %>% group_by(year, Price_Dollar, Product) %>% ggplot() +\n#  geom_line(mapping=aes(y=Price_Dollar, x=Year, color=Product), na.rm=TRUE)\n\n\n\nChicken Data Conclusion\nThe graph above suggests that the price of most chicken cuts remain relatively similar over time, however B/S Breast or boneless chicken breast appears to have increased in price over recent years. Thighs have also remained relatively similar\nNoah Milstein\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:45:13-04:00",
    "input_file": "noahdata.knit.md"
  },
  {
    "path": "posts/2021-08-17-jason-wierzbowski-exploring-eggs/",
    "title": "Jason Wierzbowski - Exploring Eggs",
    "description": "A data set about eggs.",
    "author": [
      {
        "name": "Jason Wierzbowski",
        "url": {}
      }
    ],
    "date": "2021-08-11",
    "categories": [],
    "contents": "\nReading in my CSV file\n\n\n\nHomework #3\n\n# A tibble: 6 × 6\n  month     year large_half_dozen large_dozen extra_large_half_dozen\n  <chr>    <dbl>            <dbl>       <dbl>                  <dbl>\n1 January   2004             126         230                    132 \n2 February  2004             128.        226.                   134.\n3 March     2004             131         225                    137 \n4 April     2004             131         225                    137 \n5 May       2004             131         225                    137 \n6 June      2004             134.        231.                   137 \n# … with 1 more variable: extra_large_dozen <dbl>\n# A tibble: 1 × 2\n  `mean(extra_large_dozen)` `mean(extra_large_half_dozen)`\n                      <dbl>                          <dbl>\n1                      287.                           186.\n\nWorking on Regression of if certain months have an impact on the number of eggs produced\n\n# A tibble: 20 × 6\n# Groups:   month [2]\n   month    year large_half_dozen large_dozen extra_large_half_dozen\n   <chr>   <dbl>            <dbl>       <dbl>                  <dbl>\n 1 January  2004             126         230                    132 \n 2 July     2004             134.        234.                   137 \n 3 January  2005             128.        234.                   136.\n 4 July     2005             128.        234.                   136.\n 5 January  2006             128.        234.                   136.\n 6 July     2006             128.        234.                   136.\n 7 January  2007             128.        234.                   136.\n 8 July     2007             132         237                    139 \n 9 January  2008             132         237                    139 \n10 July     2008             174.        278.                   186.\n11 January  2009             174.        278.                   186.\n12 July     2009             174.        278.                   186.\n13 January  2010             174.        272.                   186.\n14 July     2010             174.        268                    186.\n15 January  2011             174.        268.                   186.\n16 July     2011             174.        270                    186.\n17 January  2012             174.        268.                   186.\n18 July     2012             173.        268.                   186.\n19 January  2013             178         268.                   188.\n20 July     2013             178         268.                   188.\n# … with 1 more variable: extra_large_dozen <dbl>\n\nThis data set contains information on how many half dozens and dozens of eggs made to be sold in a given month of a given year.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:46:11-04:00",
    "input_file": "jason-wierzbowski-exploring-eggs.knit.md"
  },
  {
    "path": "posts/2021-08-18-rhyslongeggs/",
    "title": "Rhys_Long_Eggs",
    "description": "This is a data set that includes records of how many cartons of eggs were sold every month in 2004-2013. I got this data from the Basic Data sets section of google classroom. This data set contains four variables.",
    "author": [
      {
        "name": "Rhys Long",
        "url": {}
      }
    ],
    "date": "2021-08-11",
    "categories": [],
    "contents": "\nPart 1: Full Dataset\n\n\nlibrary(tidyverse)\nlibrary(ggplot2)\neggs_data <- read.csv(file = \"../../_data/eggs_tidy.csv\")\ntibble(eggs_data)\n\n\n# A tibble: 120 × 6\n   month      year large_half_dozen large_dozen extra_large_half_dozen\n   <chr>     <int>            <dbl>       <dbl>                  <dbl>\n 1 January    2004             126         230                    132 \n 2 February   2004             128.        226.                   134.\n 3 March      2004             131         225                    137 \n 4 April      2004             131         225                    137 \n 5 May        2004             131         225                    137 \n 6 June       2004             134.        231.                   137 \n 7 July       2004             134.        234.                   137 \n 8 August     2004             134.        234.                   137 \n 9 September  2004             130.        234.                   136.\n10 October    2004             128.        234.                   136.\n# … with 110 more rows, and 1 more variable: extra_large_dozen <dbl>\n\nggplot(data = eggs_data, aes(year)) +\n  geom_point(mapping = aes(y=extra_large_dozen), color = 'magenta') +\n  geom_point(mapping = aes(y=large_dozen), color = 'purple') +\n  geom_point(mapping = aes(y=extra_large_half_dozen), color = 'blue') +\n  geom_point(mapping = aes(y=large_half_dozen), color = 'cyan') +\n  labs(title=\"Eggs Sales in 2004-2013\", y=\"Eggs Sold\", x=\"Year\")\n\n\n\n\nPart 2: Using Filter And Summarize\n\n\nfirst_third <- filter(eggs_data, year <= 2007)\nggplot(data = first_third, aes(year)) +\n  geom_point(mapping = aes(y=extra_large_dozen), color = 'magenta') +\n  geom_point(mapping = aes(y=large_dozen), color = 'purple') +\n  geom_point(mapping = aes(y=extra_large_half_dozen), color = 'blue') +\n  geom_point(mapping = aes(y=large_half_dozen), color = 'cyan') +\n  labs(title=\"Eggs Sales in 2004-2007\", y=\"Earnings\", x=\"Year\")\n\n\n\nsummarize(first_third, max(extra_large_dozen), min(extra_large_dozen), median(extra_large_dozen), mean(extra_large_dozen))\n\n\n  max(extra_large_dozen) min(extra_large_dozen)\n1                    245                    230\n  median(extra_large_dozen) mean(extra_large_dozen)\n1                       241                241.0833\n\nsummarize(first_third, max(large_dozen), min(large_dozen), median(large_dozen), mean(large_dozen))\n\n\n  max(large_dozen) min(large_dozen) median(large_dozen)\n1              237              225               233.5\n  mean(large_dozen)\n1          233.4844\n\nsummarize(first_third, max(extra_large_half_dozen), min(extra_large_half_dozen), median(extra_large_half_dozen), mean(extra_large_half_dozen))\n\n\n  max(extra_large_half_dozen) min(extra_large_half_dozen)\n1                         139                         132\n  median(extra_large_half_dozen) mean(extra_large_half_dozen)\n1                          135.5                     136.3854\n\nsummarize(first_third, max(large_half_dozen), min(large_half_dozen), median(large_half_dozen), mean(large_half_dozen))\n\n\n  max(large_half_dozen) min(large_half_dozen)\n1                 133.5                   126\n  median(large_half_dozen) mean(large_half_dozen)\n1                    128.5               129.7266\n\n\n\nmiddle_third <- filter(eggs_data, year >= 2007 & year <=2010)\nggplot(data = middle_third, aes(year)) +\n  geom_point(mapping = aes(y=extra_large_dozen), color = 'magenta') +\n  geom_point(mapping = aes(y=large_dozen), color = 'purple') +\n  geom_point(mapping = aes(y=extra_large_half_dozen), color = 'blue') +\n  geom_point(mapping = aes(y=large_half_dozen), color = 'cyan') +\n  labs(title=\"Eggs Sales in 2007-2010\", y=\"Earnings\", x=\"Year\")\n\n\n\nsummarize(middle_third, max(extra_large_dozen), min(extra_large_dozen), median(extra_large_dozen), mean(extra_large_dozen))\n\n\n  max(extra_large_dozen) min(extra_large_dozen)\n1                  285.5                  241.5\n  median(extra_large_dozen) mean(extra_large_dozen)\n1                     285.5                271.0651\n\nsummarize(middle_third, max(large_dozen), min(large_dozen), median(large_dozen), mean(large_dozen))\n\n\n  max(large_dozen) min(large_dozen) median(large_dozen)\n1            277.5            233.5                 268\n  mean(large_dozen)\n1          260.1797\n\nsummarize(middle_third, max(extra_large_half_dozen), min(extra_large_half_dozen), median(extra_large_half_dozen), mean(extra_large_half_dozen))\n\n\n  max(extra_large_half_dozen) min(extra_large_half_dozen)\n1                       185.5                       135.5\n  median(extra_large_half_dozen) mean(extra_large_half_dozen)\n1                          185.5                     168.9401\n\nsummarize(middle_third, max(large_half_dozen), min(large_half_dozen), median(large_half_dozen), mean(large_half_dozen))\n\n\n  max(large_half_dozen) min(large_half_dozen)\n1                 174.5                 128.5\n  median(large_half_dozen) mean(large_half_dozen)\n1                    174.5               159.3568\n\n\n\nfinal_third <- filter(eggs_data, year >=2010)\nggplot(data = final_third, aes(year)) +\n  geom_point(mapping = aes(y=extra_large_dozen), color = 'magenta') +\n  geom_point(mapping = aes(y=large_dozen), color = 'purple') +\n  geom_point(mapping = aes(y=extra_large_half_dozen), color = 'blue') +\n  geom_point(mapping = aes(y=large_half_dozen), color = 'cyan') +\n  labs(title=\"Eggs Sales in 2010-2013\", y=\"Earnings\", x=\"Year\")\n\n\n\nsummarize(final_third, max(extra_large_dozen), min(extra_large_dozen), median(extra_large_dozen), mean(extra_large_dozen))\n\n\n  max(extra_large_dozen) min(extra_large_dozen)\n1                    290                  285.5\n  median(extra_large_dozen) mean(extra_large_dozen)\n1                     285.5                 287.375\n\nsummarize(final_third, max(large_dozen), min(large_dozen), median(large_dozen), mean(large_dozen))\n\n\n  max(large_dozen) min(large_dozen) median(large_dozen)\n1            271.5            267.5               267.5\n  mean(large_dozen)\n1          268.1042\n\nsummarize(final_third, max(extra_large_half_dozen), min(extra_large_half_dozen), median(extra_large_half_dozen), mean(extra_large_half_dozen))\n\n\n  max(extra_large_half_dozen) min(extra_large_half_dozen)\n1                      188.13                       185.5\n  median(extra_large_half_dozen) mean(extra_large_half_dozen)\n1                          185.5                     186.2671\n\nsummarize(final_third, max(large_half_dozen), min(large_half_dozen), median(large_half_dozen), mean(large_half_dozen))\n\n\n  max(large_half_dozen) min(large_half_dozen)\n1                   178                173.25\n  median(large_half_dozen) mean(large_half_dozen)\n1                    174.5               175.3646\n\nPart 3: Using Select, Slice, and Arrange\n\n\neggs_data %>%\n  select(month, year, extra_large_dozen) %>%\n  arrange(desc(extra_large_dozen)) %>%\n  slice(1:10)\n\n\n      month year extra_large_dozen\n1  November 2012               290\n2  December 2012               290\n3   January 2013               290\n4  February 2013               290\n5     March 2013               290\n6     April 2013               290\n7       May 2013               290\n8      June 2013               290\n9      July 2013               290\n10   August 2013               290\n\nggplot(data = eggs_data, aes(year)) +\n  geom_point(mapping = aes(y=extra_large_dozen), color = 'magenta') +\n  labs(title=\"Extra Large Dozen Egg Sales in 2004-2013\", y=\"Earnings\", x=\"Year\")\n\n\n\n\n\n\neggs_data %>%\n  select(month, year, large_dozen) %>%\n  arrange(desc(large_dozen)) %>%\n  slice(1:10)\n\n\n       month year large_dozen\n1       June 2008       277.5\n2       July 2008       277.5\n3     August 2008       277.5\n4  September 2008       277.5\n5    October 2008       277.5\n6   November 2008       277.5\n7   December 2008       277.5\n8    January 2009       277.5\n9   February 2009       277.5\n10     March 2009       277.5\n\nggplot(data = eggs_data, aes(year)) +\n  geom_point(mapping = aes(y=large_dozen), color = 'purple') +\n  labs(title=\"Large Dozen Egg Sales in 2004-2013\", y=\"Earnings\", x=\"Year\")\n\n\n\n\n\n\neggs_data %>%\n  select(month, year, extra_large_half_dozen) %>%\n  arrange(desc(extra_large_half_dozen)) %>%\n  slice(1:10)\n\n\n      month year extra_large_half_dozen\n1  November 2012                 188.13\n2  December 2012                 188.13\n3   January 2013                 188.13\n4  February 2013                 188.13\n5     March 2013                 188.13\n6     April 2013                 188.13\n7       May 2013                 188.13\n8      June 2013                 188.13\n9      July 2013                 188.13\n10   August 2013                 188.13\n\nggplot(data = eggs_data, aes(year)) +\n  geom_point(mapping = aes(y=extra_large_half_dozen), color = 'blue') +\n  labs(title=\"Extra Large Half Dozen Egg Sales in 2004-2013\", y=\"Earnings\", x=\"Year\")\n\n\n\n\n\n\neggs_data %>%\n  select(month, year, large_half_dozen) %>%\n  arrange(desc(large_half_dozen)) %>%\n  slice(1:10)\n\n\n      month year large_half_dozen\n1  November 2012              178\n2  December 2012              178\n3   January 2013              178\n4  February 2013              178\n5     March 2013              178\n6     April 2013              178\n7       May 2013              178\n8      June 2013              178\n9      July 2013              178\n10   August 2013              178\n\nggplot(data = eggs_data, aes(year)) +\n  geom_point(mapping = aes(y=large_half_dozen), color = 'cyan') +\n  labs(title=\"Large Half Dozen Egg Sales in 2004-2013\", y=\"Earnings\", x=\"Year\")\n\n\n\n\nPart 4: Using Rename, Pivot_Longer, and Mutate\n\n\neggs_data %>%\n  rename(\"Month\"=month, \"Year\"=year) %>%\n  pivot_longer(cols=large_half_dozen:extra_large_dozen,\n               names_to = c(\"Size\", \"Quantity\"),\n               names_sep=\"arge_\",\n               values_to = \"Earnings\")%>%\n  mutate(Size = case_when(\n    Size == 'l'~\"Large\",\n    Size == 'extra_l'~ \"Extra Large\")) %>%\n  mutate(Quantity=case_when(\n    Quantity == \"half_dozen\" ~ \"Half Dozen\",\n    Quantity == \"dozen\" ~ \"Dozen\"))\n\n\n# A tibble: 480 × 5\n   Month     Year Size        Quantity   Earnings\n   <chr>    <int> <chr>       <chr>         <dbl>\n 1 January   2004 Large       Half Dozen     126 \n 2 January   2004 Large       Dozen          230 \n 3 January   2004 Extra Large Half Dozen     132 \n 4 January   2004 Extra Large Dozen          230 \n 5 February  2004 Large       Half Dozen     128.\n 6 February  2004 Large       Dozen          226.\n 7 February  2004 Extra Large Half Dozen     134.\n 8 February  2004 Extra Large Dozen          230 \n 9 March     2004 Large       Half Dozen     131 \n10 March     2004 Large       Dozen          225 \n# … with 470 more rows\n\n\n\n\n",
    "preview": "posts/2021-08-18-rhyslongeggs/rhyslongeggs_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-08-20T15:46:33-04:00",
    "input_file": "rhyslongeggs.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-08-11-saulo-homework-one/",
    "title": "Saulo Homework One",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Saulo DePaula",
        "url": {}
      }
    ],
    "date": "2021-08-11",
    "categories": [],
    "contents": "\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:45:17-04:00",
    "input_file": "saulo-homework-one.knit.md"
  },
  {
    "path": "posts/2021-08-11-post-1-hmwk-1/",
    "title": "Post 1 HMWK 1",
    "description": "This is my post for the first homework",
    "author": [
      {
        "name": "Annie McGrew",
        "url": {}
      }
    ],
    "date": "2021-08-11",
    "categories": [
      "homework 1",
      "Annie McGrew"
    ],
    "contents": "\n\n\nknitr::opts_chunk$set(echo = FALSE)\nvector <- c(1,2,3,4,5)\nnew_vector <- c(3,5,1,1,2)\navg_vector <- (vector + new_vector)/2\nperc_vector <- avg_vector/5\nfinal_vector <- perc_vector*100\n\n\n\nFirst I input two vectors: vector = 1, 2, 3, 4, 5 and new_vector = 3, 5, 1, 1, 2 Then I take the average of these two vectors creating avg_vector = 2, 3.5, 2, 2.5, 3.5 Then I divide the average of the vectors by 5 (perc_vector = 0.4, 0.7, 0.4, 0.5, 0.7) and finally I multiple the vector by 100 (final_vector = 40, 70, 40, 50, 70).\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:45:15-04:00",
    "input_file": "post-1-hmwk-1.knit.md"
  },
  {
    "path": "posts/2021-08-10-cars/",
    "title": "iris",
    "description": "iris dataset| ErinTracy",
    "author": [],
    "date": "2021-08-10",
    "categories": [
      "-homework 3"
    ],
    "contents": "\nColumn 1\nWidth\n\n\nggplot(iris, aes(Petal.Width)) + geom_histogram(binwidth = 0.1)\n\n\n\n\nlength\n\n\nggplot(iris, aes(Petal.Length)) + geom_bar()\n\n\n\n\nSpecies\n\n\nggplot(iris, aes(Species)) + geom_bar()\n\n\n\n\nColumn 2\nThe largest iris\n\n\niris %>% \n  arrange(desc(Petal.Length)) %>% \n  head(100) %>% \n  select(Petal.Length, Petal.Width, Species) %>% \n  DT::datatable()\n\n\n\n{\"x\":{\"filter\":\"none\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\"],[6.9,6.7,6.7,6.6,6.4,6.3,6.1,6.1,6.1,6,6,5.9,5.9,5.8,5.8,5.8,5.7,5.7,5.7,5.6,5.6,5.6,5.6,5.6,5.6,5.5,5.5,5.5,5.4,5.4,5.3,5.3,5.2,5.2,5.1,5.1,5.1,5.1,5.1,5.1,5.1,5.1,5,5,5,5,4.9,4.9,4.9,4.9,4.9,4.8,4.8,4.8,4.8,4.7,4.7,4.7,4.7,4.7,4.6,4.6,4.6,4.5,4.5,4.5,4.5,4.5,4.5,4.5,4.5,4.4,4.4,4.4,4.4,4.3,4.3,4.2,4.2,4.2,4.2,4.1,4.1,4.1,4,4,4,4,4,3.9,3.9,3.9,3.8,3.7,3.6,3.5,3.5,3.3,3.3,3],[2.3,2.2,2,2.1,2,1.8,2.5,1.9,2.3,2.5,1.8,2.1,2.3,2.2,1.8,1.6,2.3,2.1,2.5,1.8,2.1,2.2,1.4,2.4,2.4,2.1,1.8,1.8,2.1,2.3,1.9,2.3,2.3,2,1.6,1.9,2,2.4,1.5,2.3,1.9,1.8,1.7,2,1.5,1.9,1.5,1.5,2,1.8,1.8,1.8,1.4,1.8,1.8,1.4,1.6,1.4,1.2,1.5,1.5,1.3,1.4,1.5,1.3,1.5,1.5,1.5,1.5,1.6,1.7,1.4,1.4,1.3,1.2,1.3,1.3,1.5,1.3,1.2,1.3,1,1.3,1.3,1.3,1,1.3,1.3,1.2,1.4,1.1,1.2,1.1,1,1.3,1,1,1,1,1.1],[\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"versicolor\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"versicolor\",\"virginica\",\"virginica\",\"virginica\",\"versicolor\",\"versicolor\",\"virginica\",\"virginica\",\"virginica\",\"versicolor\",\"versicolor\",\"virginica\",\"virginica\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"virginica\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\"]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Petal.Length<\\/th>\\n      <th>Petal.Width<\\/th>\\n      <th>Species<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\n\n\n\n",
    "preview": "posts/2021-08-10-cars/cars_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-08-20T15:44:26-04:00",
    "input_file": "cars.knit.md",
    "preview_width": 960,
    "preview_height": 320
  },
  {
    "path": "posts/2021-08-10-hello-world/",
    "title": "Hello World",
    "description": "Marina's first attempt at using distill",
    "author": [
      {
        "name": "Marina",
        "url": {}
      }
    ],
    "date": "2021-08-10",
    "categories": [],
    "contents": "\nTime to read in data. Start with an easy one\n\n\n\n\n# A tibble: 6 × 32\n  hotel        is_canceled lead_time arrival_date_ye… arrival_date_mo…\n  <chr>              <dbl>     <dbl>            <dbl> <chr>           \n1 Resort Hotel           0       342             2015 July            \n2 Resort Hotel           0       737             2015 July            \n3 Resort Hotel           0         7             2015 July            \n4 Resort Hotel           0        13             2015 July            \n5 Resort Hotel           0        14             2015 July            \n6 Resort Hotel           0        14             2015 July            \n# … with 27 more variables: arrival_date_week_number <dbl>,\n#   arrival_date_day_of_month <dbl>, stays_in_weekend_nights <dbl>,\n#   stays_in_week_nights <dbl>, adults <dbl>, children <dbl>,\n#   babies <dbl>, meal <chr>, country <chr>, market_segment <chr>,\n#   distribution_channel <chr>, is_repeated_guest <dbl>,\n#   previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>, …\n\nTry a harder one: an excel file with a number of useless rows\n\n# A tibble: 6 × 17\n  blank pay_grade SWOC_male SWOC_female SWOC_total SWC_male SWC_female\n  <chr> <chr>         <dbl>       <dbl>      <dbl>    <dbl>      <dbl>\n1 <NA>  E-1           31229        5717      36946      563        122\n2 <NA>  E-2           53094        8388      61482     1457        275\n3 <NA>  E-3          131091       21019     152110     4264       1920\n4 <NA>  E-4          112710       16381     129091     9491       4662\n5 <NA>  E-5           57989       11021      69010    10937       6576\n6 <NA>  E-6           19125        4654      23779    10369       4962\n# … with 10 more variables: SWC_total <dbl>, JSM_male <dbl>,\n#   JSM_female <dbl>, JSM_total <dbl>, CM_male <dbl>,\n#   CM_female <dbl>, CM_total <dbl>, Total_Male <dbl>,\n#   Total_Female <dbl>, Total_Total <dbl>\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:44:35-04:00",
    "input_file": "hello-world.knit.md"
  },
  {
    "path": "posts/2021-08-10-homework-1/",
    "title": "Homework 1",
    "description": "Homework 1",
    "author": [],
    "date": "2021-08-10",
    "categories": [],
    "contents": "\nHello, my name is Shih-Yen Pan. I am a PhD student in Economics at UMass, Amherst.\nIn this post, I will introduce the Two Sum problem from LeetCode and a solution using double for loop provided by Pascal Schmidt here. I thought it might be useful to see what for loop looks like in R.\nThe idea of the problem is, given a list of integers nums and an integer target, to write a function that spits out, if they exist, two different integers in nums that sum up to the target integer.\ntwo_sum <- function(nums, target) {\n\n  for(i in seq_along(nums)) {\n    for(j in seq_along(nums)[-length(nums)]) {\n      \n      sum <- nums[i] + nums[j + 1]\n      if(sum == target) {\n        \n        first <- i\n        second <- j + 1\n        output <- c(nums[first], nums[second])\n        return(output)\n        \n      }\n      \n    }\n    \n  }\n  \n}\nThis is what the function two_sum is doing: Starting from the beginning of the vector ‘nums’, for each integer, search the rest of vector using the second for loop. If the two numbers sum up to the target integer, the code returns those two numbers; otherwise, continue doing the same with the next integer in the list.\nExample:\nnums <- c(1, 2, 3, 5, 6, 9, 11)\ntarget <- 9\ntwo_sum(nums, target)\nThis should return 3 and 6.\nTry it out yourself with different numbers! How can the code be modified to return all the different pairs that sum to the target integer?\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:44:37-04:00",
    "input_file": "homework-1-Shih-Yen.knit.md"
  },
  {
    "path": "posts/2021-08-10-hw01/",
    "title": "HW01",
    "description": "A short description of the post.",
    "author": [],
    "date": "2021-08-10",
    "categories": [],
    "contents": "\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:44:39-04:00",
    "input_file": "hw01.knit.md"
  },
  {
    "path": "posts/2021-08-10-iris/",
    "title": "iris",
    "description": "Here is the iris dataset.",
    "author": [
      {
        "name": "bakharia",
        "url": {}
      }
    ],
    "date": "2021-08-10",
    "categories": [
      "homework 3",
      "iris",
      "bakharia"
    ],
    "contents": "\nHere is a plot of the iris dataset:\n\n\nlibrary(datasets)\nplot(iris)\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-08-10-iris/iris_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-08-20T15:44:41-04:00",
    "input_file": "iris.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-08-10-meet-rhys/",
    "title": "Meet Rhys",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Rhys Long",
        "url": {}
      }
    ],
    "date": "2021-08-10",
    "categories": [
      "homework one",
      "introduce yourself",
      "rhys long"
    ],
    "contents": "\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:44:43-04:00",
    "input_file": "meet-rhys.knit.md"
  },
  {
    "path": "posts/2021-08-10-michelle-manning/",
    "title": "Michelle Manning",
    "description": "Intro for me.",
    "author": [
      {
        "name": "Michelle Manning",
        "url": {}
      }
    ],
    "date": "2021-08-10",
    "categories": [],
    "contents": "\n\n\nlibrary(dslabs)\ndata(\"gapminder\")\nlibrary(dplyr)\nlibrary(ggplot2)\n\n\n\n\n\ngapminder %>% \n  select(continent, region, gdp, population) %>%\n  mutate(gdp_per_capita = gdp / population) %>% \n  arrange(desc(gdp_per_capita)) %>%\n  ggplot(aes(x=gdp_per_capita)) + \n  geom_histogram(binwidth = 30)\n\n\n\n\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": "posts/2021-08-10-michelle-manning/michelle-manning_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2021-08-20T15:44:46-04:00",
    "input_file": "michelle-manning.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-08-10-noahblogpost/",
    "title": "Noahblogpost",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Noah Milstein",
        "url": {}
      }
    ],
    "date": "2021-08-10",
    "categories": [],
    "contents": "\n\n\n8+8\n\n\n[1] 16\n\n\n\n8==2\n\n\n[1] FALSE\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:44:48-04:00",
    "input_file": "noahblogpost.knit.md"
  },
  {
    "path": "posts/2021-08-10-test/",
    "title": "TEST",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "bakharia",
        "url": {}
      }
    ],
    "date": "2021-08-10",
    "categories": [],
    "contents": "\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:44:50-04:00",
    "input_file": "test.knit.md"
  },
  {
    "path": "posts/2021-08-10-title/",
    "title": "title",
    "description": "A short description of the post.",
    "author": [],
    "date": "2021-08-10",
    "categories": [],
    "contents": "\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:44:52-04:00",
    "input_file": "title.knit.md"
  },
  {
    "path": "posts/2021-08-10-zoes-post/",
    "title": "Zoe's Post",
    "description": "my first post",
    "author": [
      {
        "name": "Zoe Bean",
        "url": {}
      }
    ],
    "date": "2021-08-10",
    "categories": [],
    "contents": "\nHi! I’m Zoe. I really like for loops. Here’s one in R!\n\n\ncool_sequence<-c(1,1,2,3,5,8,13,21,34)\ntotal<-0\nfor (el in cool_sequence) {\n  total=total+el\n}\nprint(total)\n\n\n[1] 88\n\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:44:53-04:00",
    "input_file": "zoes-post.knit.md"
  },
  {
    "path": "posts/2021-08-07-still-learning-githib-workflow/",
    "title": "Still Learning the GitHib Workflow",
    "description": "Fingers crossed this post works",
    "author": [
      {
        "name": "Maddi Hertz",
        "url": {}
      }
    ],
    "date": "2021-08-07",
    "categories": [],
    "contents": "\nUsing Markdown is fun!\nI learned a lot this summer — Markdown is your friend, as are flexdashboard and Stack Overflow.\nAlso, always keep in mind that social scientists understand data and data management just as well (if not better) than the computer scientists.\nTidyTuesday\nNew goal: Participate in Tidy Tuesdays\nExample of R Chunk\n\n\n2+2\n\n\n[1] 4\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:44:22-04:00",
    "input_file": "still-learning-githib-workflow.knit.md"
  },
  {
    "path": "posts/2021-08-07-welcome/",
    "title": "Welcome to DACSS 601",
    "description": "August 2021 Orientation Session",
    "author": [
      {
        "name": "Meredith Rolfe",
        "url": "http://umass.edu/sbs/dacss"
      }
    ],
    "date": "2021-08-06",
    "categories": [
      "welcome"
    ],
    "contents": "\nWelcome to the Data Analytics and Computational Social Science Programs’ Orientation 2021 session of DACSS 601 Foundations of Data Science. This blog will feature the work of our incoming M.S. students taking the class, as well as PhD students in the College of Behavioral and Social Sciences who have decided to participate through “R Bootcamp”.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-20T15:44:23-04:00",
    "input_file": "welcome.knit.md"
  }
]
